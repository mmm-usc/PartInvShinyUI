---
title: "Applied Examples 2"
author: "Meltem Ozcan"
date: "5/9/2022"
output: html_document
---

```{r setup, warning=FALSE, message=FALSE}
knitr::opts_chunk$set(echo = TRUE)
library(PartInvShinyUI)
library(lavaan)
```
## Example 2:  Millsap, Kwok (2004)
'Evaluating the Impact of Partial Factorial Invariance on
Selection in Two Populations'

Worry Subscale of the Test Anxiety Inventory (TAI), biased items: 3, 4
```{r}
# Worry subscale of the test anxiety inventory
ex2 <- item_deletion_h(weights_item = c(1, 1, 1, 1, 1, 1, 1, 1), 
                              #propsel = 0.1000001,#"90% cutpoint"
                              cut_z= 23.29952,
                             n_dim = 1,  
                             alpha_r = 0,
                             alpha_f =-0.126,
                             psi_r = 0.544,
                             psi_f = 0.477,
                             lambda_r = c(0.836, 1, 0.904, 0.808, 0.903,
                                             0.960, 0.934, 0.934),
                             lambda_f = c(0.836, 1, 1.111, 1.001, 0.903, 
                                             0.960, 0.934, 0.934),
                             nu_r = c(2.114, 2.064, 1.901, 2.004, 2.144,
                                        1.985, 2.179, 2.230),
                             nu_f= c(2.114, 2.064, 1.880, 1.985, 2.144,
                                        1.985, 2.179, 2.230),
                             Theta_r = diag(c(.517, .523, .631, .585, .481,
                                                .469,.551,.572)),
                             Theta_f = diag(c(.514, .407, .371, .475, .392,
                                                .335,.454,.457)),
                             weights_latent = 1,
                             plot_contour = FALSE,
                             print_detailed = FALSE, pmix_ref = 0.5)
```



```{r}
ex2
```

The positive h values in h_overall_CAI_par suggest that no item should be 
dropped, as dropping any of the items would lead to a lower success ratio, lower
sensitivity, and lower specificity.

If the focal group followed the same distribution as the reference group, a larger
proportion would be selected for the focal group compared to the reference group 
(indicated by the negative PS) when all items are used. If any one item is dropped
there would be an increase in PS for the reference group, leading to a positive h.




A greater proportion is selected under SFI compared to PFI when all items are used, but when any of the 8 items are dropped, a 
greater proportion is selected under PFI. SR, SE, SP are always
positive, indicating that regardless of item drop condition, 
SR, SE, SP under SFI is always larger than SR, SE, SP under PFI. 



## Example 3: Mini-IPIP - Ock, McAbee, Mulfinger, and Oswald (2020)
'The Practical Effects of Measurement Invariance: Gender Invariance in Two Big Five Personality Measures'
Biased items: 1, 7, 11, 13, 14
```{r read data, include  = FALSE}
data <- read.table("IPIPFFM.dat", header = TRUE)
head(data)
male <- data[data$sex == 1, ]
female <- data[data$sex == 2, ]
```

```{r specify and fit model}
model <- 'A =~  a2 + a5  + a7 + a9
          C =~  c3 + c4 + c8 + c9
          E =~ e1 + e4 + e6 + e7
          N =~ n1 + n2 + n6 + n8
          O =~ i2 + i8 + i9 + i10
          a2 ~~ a5
          e4 ~~ e7  
          i2 ~~ i10
          i8 ~~ i9
          a9 ~~ i9
          c3 ~~ e6
          a2 ~~ e7
          e7 ~~ n2'
fit_strict <- cfa(model, data = data, group = "sex",
                  group.equal = c("loadings", "Intercepts", "residuals"),
                  group.partial = c("e6 ~ 1", "n1 ~ 1", "n2 ~ 1", "a2 ~ 1", 
                                    #items  1 (A2), 7 (C8), 11 (E6), 13 (N1), 14 (N2)
                                    "n2 ~~ n2", "n1 ~~ n1", "c8 ~~ c8"),
                  estimator = "MLR", std.lv = TRUE)
result <- lavInspect(fit_strict, what = "est")
```

```{r IPIPFFM item deletion}
ex3 <- item_deletion_h(propsel=0.25,
              weights_item = c(3.1385, 3.1385, 3.1385, 3.1385,
                                8.3203, 8.3203, 8.3203, 8.3203,
                                5.1586, 5.1586, 5.1586, 5.1586,
                                -6.5870, -6.5870, -6.5870, -6.5870,
                                1.7957, 1.7957, 1.7957, 1.7957), 
              n_dim = 5, 
              alpha_r = result[[2]]$alpha,
              alpha_f = result[[1]]$alpha,
              psi_r = result[[2]]$psi,
              psi_f = result[[1]]$psi,
              lambda_r = result[[2]]$lambda,
              lambda_f = result[[1]]$lambda,
              nu_r = result[[2]]$nu,
              nu_f = result[[1]]$nu,
              Theta_r = result[[2]]$theta,
              Theta_f = result[[1]]$theta,
              weights_latent = c(0.12553907, 0.33281060, 0.20634298, 
                                 -0.26347936, 0.07182799),
              plot_contour = FALSE, 
              print_detailed = FALSE)
              #user_specified_items = c(1,7,11,13,14))
```

```{r}
ex3
```

We see that dropping item 1 would lead to
a marginal improvement in composite SR and composite SP, while composite SE would be unaffected. We see a similar
pattern with item 18. 

Item 12 appears to be a bad item to drop as dropping this item produces the highest
h values (i.e., the largest decrease in SR, SE, and SP) in this example, followed
by items 10 and 11. Conversely, removing item 4 would not harm SR, SP, or SE.

Out of the biased items (1, 7, 11, 13, and 14), we should consider dropping item 1
and retaining item 11.

When item 11 is dropped, h for PS is negative (a higher proportion is selected 
under Efocal than the reference group). For all other item drop conditions, h for 
PS is positive. 