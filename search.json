[{"path":[]},{"path":"https://mmm-usc.github.io/unbiasr/articles/item-deletion-examples.html","id":"classification-accuracy-indices-cai","dir":"Articles","previous_headings":"Formulas and Notation","what":"Classification Accuracy Indices (CAI)","title":"Applied examples of item deletion statistics","text":"Proportion Selected: \\(\\text{PS}=\\text{P(TP)}+\\text{P(FP)}\\) Success Ratio: \\(\\text{SR}=\\dfrac{\\text{P(TP)}}{\\text{P(TP)}+\\text{P(FP)}}\\) Sensitivity: \\(\\text{SE}=\\dfrac{\\text{P(TP)}}{\\text{P(TP)}+\\text{P(FN)}}\\) Specificity: \\(\\text{SP}=\\dfrac{\\text{P(TN)}}{\\text{P(TN)}+\\text{P(FP)}}\\) Unless otherwise indicated, assume full item set (length $\\(J\\)) used partial factorial invariance (PFI) holds. strict factorial invariance (SFI) holds, denoted \\(\\text{CAI}_{\\text{sfi}}\\), e.g., \\(\\text{SE}_{\\text{sfi}}\\) SE SFI. CAI computed item set excluding item \\(j \\\\{1,\\ldots,J\\}\\) denoted \\(\\text{CAI}^{|j}\\), e.g., \\(\\text{SE}^{|2}\\) SE computed item set excluding second item.","code":""},{"path":"https://mmm-usc.github.io/unbiasr/articles/item-deletion-examples.html","id":"aggregate-classification-accuracy-indices-leftoverlinetextcairight","dir":"Articles","previous_headings":"Formulas and Notation","what":"Aggregate Classification Accuracy Indices \\(\\left(\\overline{\\text{CAI}}\\right)\\)","title":"Applied examples of item deletion statistics","text":"Given \\(p_f = 1 - p_r\\), Aggregate SR: \\[\\overline{\\text{SR}} = \\dfrac{\\text{TP}_{r}\\times p_r + \\text{TP}_{f}\\times p_f}{\\text{TP}_{r}\\times p_r + \\text{TP}_{f}\\times p_f + \\text{FP}_{r}\\times p_r + \\text{FP}_{f}\\times p_f}\\] Aggregate SE: \\[\\overline{\\text{SE}} = \\dfrac{\\text{TP}_{r}\\times p_r + \\text{TP}_{f}\\times p_f}{\\text{TP}_{r}\\times p_r + \\text{TP}_{f}\\times p_f + \\text{FN}_{r}\\times p_r + \\text{FN}_{f}\\times p_f}\\] Aggregate SP: \\[\\overline{\\text{SP}} = \\dfrac{\\text{TN}_{r}\\times p_r + \\text{TN}_{f}\\times p_f}{\\text{TN}_{r}\\times p_r + \\text{TN}_{f}\\times p_f + \\text{FP}_{r}\\times p_r + \\text{FP}_{f}\\times p_f}\\] \\(\\overline{\\text{CAI}}\\) computed partial invariance case (hence, comparison discuss relation \\(\\overline{\\text{CAI}}\\) item deletion).","code":""},{"path":[]},{"path":"https://mmm-usc.github.io/unbiasr/articles/item-deletion-examples.html","id":"impact-of-removing-an-item-on-overlinetextcai","dir":"Articles","previous_headings":"Indices for the impact of item bias","what":"Impact of removing an item on \\(\\overline{\\text{CAI}}\\)","title":"Applied examples of item deletion statistics","text":"\\(h^{|j}\\overline{\\text{CAI}}\\): Cohen’s \\(h\\) effect size improvement/decrease aggregate CAI PFI \\(j\\)-th item removed: \\[h^{|j}\\overline{\\text{CAI}} = 2\\arcsin\\left(\\sqrt{\\overline{\\text{CAI}}}\\right)-2\\arcsin\\left(\\sqrt{\\overline{\\text{CAI}}^{|j}}\\right)\\] negative \\(h^{|j}\\overline{\\text{CAI}}\\) indicates improvement (\\(h^{|j}\\overline{\\text{CAI}}<0 \\iff \\overline{\\text{CAI}}<\\overline{\\text{CAI}}^{|j}\\)) whereas positive \\(h^{|j}\\overline{\\text{CAI}}\\) indicates deterioration performance.","code":""},{"path":"https://mmm-usc.github.io/unbiasr/articles/item-deletion-examples.html","id":"comparing-cai-for-reference-r-vs--expected-focal-ef-groups","dir":"Articles","previous_headings":"Indices for the impact of item bias","what":"Comparing CAI for reference (R) vs. expected focal (Ef) groups","title":"Applied examples of item deletion statistics","text":"\\(h^{\\text{r-Ef}}\\text{CAI}\\): Cohen’s \\(h\\) effect size quantifying discrepancy \\(\\text{CAI}_{\\text{r}}\\) vs. \\(\\text{Ef}\\) full set items PFI. \\[ \\begin{align*} h^{\\text{r-Ef}}\\text{CAI}&= 2\\text{arcsin}\\left(\\sqrt{\\text{CAI}_{ \\text{r}}}\\right)-2\\text{arcsin}\\left(\\sqrt{\\text{CAI}_{\\text{Ef}}}\\right) \\end{align*} \\] \\(h^{\\text{r-Ef}}\\text{CAI}^{|j}\\): Cohen’s \\(h\\) effect size quantifying discrepancy \\(\\text{CAI}_{\\text{r}}^{|j}\\) vs. \\(\\text{CAI}_{\\text{Ef}}^{|j}\\) item set excluding item \\(j\\) PFI. \\[ \\begin{align*} h^{\\text{r-Ef}}\\text{CAI}^{|j} &= 2\\text{arcsin}\\left(\\sqrt{\\text{CAI}_{ \\text{r}}^{|j}}\\right)-2\\text{arcsin}\\left(\\sqrt{\\text{CAI}_{\\text{Ef}}^{|j}}\\right) \\end{align*} \\]","code":""},{"path":"https://mmm-usc.github.io/unbiasr/articles/item-deletion-examples.html","id":"impact-of-removing-an-item-on-the-discrepancy-between-htextr-eftextcai-vs--htextr-eftextcaij","dir":"Articles","previous_headings":"Indices for the impact of item bias","what":"Impact of removing an item on the discrepancy between \\(h^{\\text{r-Ef}}\\text{CAI}\\) vs. \\(h^{\\text{r-Ef}}\\text{CAI}^{|j}\\)","title":"Applied examples of item deletion statistics","text":"\\(\\Delta^{|j} h^{\\text{r-Ef}}\\text{CAI}\\): Cohen’s \\(h\\) effect size quantifying discrepancy \\(h^{\\text{r-Ef}}\\text{CAI}\\) vs. \\(h^{\\text{r-Ef}}\\text{CAI}^{|j}\\). words, effect size change bias \\(j\\)-th item dropped. \\[ \\begin{align*} \\Delta^{|j} h^{\\text{r-Ef}}\\text{CAI}&= | h^{\\text{r-Ef}}\\text{CAI}| - | h^{\\text{r-Ef}}\\text{CAI}^{|j}| \\end{align*} \\]","code":""},{"path":"https://mmm-usc.github.io/unbiasr/articles/item-deletion-examples.html","id":"illustrative-example-ces-d","dir":"Articles","previous_headings":"","what":"Illustrative Example: CES-D","title":"Applied examples of item deletion statistics","text":"Example based Zhang et al.’s 2011 examination Center Epidemiological Studies Depression (CES-D) Scale (Radloff, 1977). first demonstrate use item deletion indices relevant functions full four-dimensional CES-D Scale, assuming selection (binary classification) based scores full scale. , demonstrate item deletion can performed scale deletion one item. Finally, demonstrate use item deletion indices single-dimensional scale treating subscale CES-D Scale separate factor, assuming classification decisions based subscale scores. analyses, consider deletion one item time.","code":"library(unbiasr) library(lavaan) # Zhang et al. (2011) BMC Medical Research Methodology, Tables 3-4 on page 7  # Reference group: Chinese, Focal group: Dutch pmix_CESD_r <- 4903/(1903+4903)  # Unstandardized factor loadings lambda_SOM_r <- lambda_SOM_f <- c(1.00, 1.03, 1.18, 1.29, 1.07, 1.02, 1.26) lambda_DEP_r <- lambda_DEP_f <- c(1.00, 1.13, 0.82, 0.91, 1.11, 0.92, 1.06) lambda_POS_r <- lambda_POS_f <- c(1.00, 1.66, 2.30, 2.29) lambda_INT_r <- lambda_INT_f <- c(1.00, 0.94)  # Unstandardized intercepts nu_SOM_r <- c(0.69, 0.56, 0.78, 0.81, 0.88, 0.74, 0.70) nu_SOM_f <- c(0.69, 0.56, 0.78, 0.80, 0.88, 0.74, 0.70) nu_DEP_r <- c(0.52, 0.55, 0.57, 0.42, 0.57, 0.50, 0.56) nu_DEP_f <- c(0.52, 0.55, 0.30, 0.42, 0.57, 0.50, 0.56) nu_POS_r <- c(1.54, 1.36, 1.16, 1.08) nu_POS_f <- c(0.68, 1.36, 1.16, 1.08) nu_INT_r <- nu_INT_f <- c(0.44, 0.41)  # Unstandardized uniqueness Theta_SOM_r <- Theta_SOM_f <- diag(c(0.45, 0.37, 0.39, 0.40, 0.57, 0.51, 0.37)) Theta_DEP_r <- diag(c(0.29, 0.30, 0.41, 0.31, 0.29, 0.27, 0.24)) Theta_DEP_f <- diag(c(0.29, 0.13, 0.09, 0.14, 0.29, 0.27, 0.24)) Theta_POS_r <- diag(c(1.20, 0.81, 0.32, 0.32)) Theta_POS_f <- diag(c(0.72, 0.81, 0.32, 0.32)) Theta_INT_r <- diag(c(0.19, 0.23)) Theta_INT_f <- diag(c(0.19, 0.08))  # Latent mean differences alpha_SOM_r <- 0 alpha_DEP_r <- 0 alpha_POS_r <- 0 alpha_INT_r <- 0 alpha_SOM_f <- -0.261 alpha_DEP_f <- -0.259 alpha_POS_f <- -0.125 alpha_INT_f <- -0.323  # Latent mean variances psi_SOM_r <- 0.482^2 psi_SOM_f <- 0.324^2 psi_DEP_r <- 0.570^2 psi_DEP_f <- 0.318^2 psi_POS_r <- 0.354^2 psi_POS_f <- 0.329^2 psi_INT_r <- 0.574^2 psi_INT_f <- 0.184^2  # Cutoff of 16/60 on full scale. 20 items, each item scored 0-3."},{"path":"https://mmm-usc.github.io/unbiasr/articles/item-deletion-examples.html","id":"full-4-factor-ces-d-scale","dir":"Articles","previous_headings":"Illustrative Example: CES-D","what":"Full 4-Factor CES-D Scale","title":"Applied examples of item deletion statistics","text":"Items 4, 9, 10, 11, 15, 19, 20 determined biased items, correspond SOM 4, DEP 2, DEP 3, DEP 4, POS 1, INT 1, INT 2 (effort, depressed, failure, fearful, good, dislike). can seen first output table, removing items leads minor decreases \\(\\overline{\\text{CAI}}\\) (lower aggregate classification accuracy), effect size small illustrated second output table. item deletion brings AI ratio closest ideal AI ratio 1 item 15, \\(AI^{|15}=0.977\\) (\\(AI=0.908\\)), indicating item strong candidate deletion. second largest increase proximity \\(AI^{|j}=1\\) achieved deletion item 10 (DEP 3), \\(AI^{|10}=0.930\\). comparison CAI reference group expected CAI focal group next table shows discrepancy \\(\\text{CAI}_r\\) \\(\\text{CAI}_{Ef}\\) becomes smallest item 15 deleted \\(h^{\\text{r-Ef}}\\text{PS}=0.085\\) goes \\(h^{\\text{r-Ef}}\\text{PS}^{|15}=0.021\\), \\(h^{\\text{r-Ef}}\\text{SR}=-0.157\\) goes \\(h^{\\text{r-Ef}}\\text{SR}^{|15}=-0.047\\), \\(h^{\\text{r-Ef}}\\text{SE}=0.141\\) goes \\(h^{\\text{r-Ef}}\\text{SE}^{|15}=0.026\\) \\(h^{\\text{r-Ef}}\\text{SP}=-0.164\\) goes \\(h^{\\text{r-Ef}}\\text{SP}^{|15}=-0.048\\). Note judge improvement difference \\(\\text{CAI}_r\\) \\(\\text{CAI}_{Ef}\\) magnitude difference rather direction. comparison CAI reference vs. Efocal groups, direction difference indicates group benefiting bias. like minimize bias regardless group membership, signs indices nevertheless give valuable information classification process. 10-th item one item appears lead reduction discrepancy \\(\\text{CAI}_r\\) \\(\\text{CAI}_{Ef}\\). Moving final table, see removing 15-th item largest impact discrepancy \\(\\text{CAI}_r\\) \\(\\text{CAI}_{Ef}\\), followed deletion 10-th item. Overall, researcher may consider deleting either 15-th 10-th item using domain specific expertise consulting existing literature choose two items. output object call item_deletion_h() contains tables may aid researcher process. instance, outputs PartInv() may examined two item deletion scenarios: items retained: Subset excluding item 15: user can also supply cut-score delete-one scenarios instead letting function compute proportions selected partial strict invariance using proportions delete-one scenarios: Let’s assume sake illustration researcher decides drop item 15 (\\(good\\)). can repeat process new item weights: items retained: Subset excluding item 10:","code":"lambda_CESD_r <- rbind(cbind(lambda_SOM_r, rep(0, 7), rep(0, 7), rep(0, 7)),                        cbind(rep(0, 7), lambda_DEP_r, rep(0, 7), rep(0, 7)),                        cbind(rep(0, 4), rep(0, 4), lambda_POS_r, rep(0, 4)),                        cbind(rep(0, 2), rep(0, 2), rep(0, 2), lambda_INT_r)) lambda_CESD_f <- rbind(cbind(lambda_SOM_f, rep(0, 7), rep(0, 7), rep(0, 7)),                        cbind(rep(0, 7), lambda_DEP_f, rep(0, 7), rep(0, 7)),                        cbind(rep(0, 4), rep(0, 4), lambda_POS_f, rep(0, 4)),                        cbind(rep(0, 2), rep(0, 2), rep(0, 2), lambda_INT_f)) psi_CESD_r <- c(psi_SOM_r, psi_DEP_r, psi_POS_r, psi_INT_r) psi_CESD_f <- c(psi_SOM_f, psi_DEP_f, psi_POS_f, psi_INT_f) alpha_CESD_r <- c(alpha_SOM_r, alpha_DEP_r, alpha_POS_r, alpha_INT_r) alpha_CESD_f <- c(alpha_SOM_f, alpha_DEP_f, alpha_POS_f, alpha_INT_f)  Theta_CESD_r <- diag(c(0.45, 0.37, 0.39, 0.40, 0.57, 0.51, 0.37, #SOM                        0.29, 0.30, 0.41, 0.31, 0.29, 0.27, 0.24, #DEP                        1.20, 0.81, 0.32, 0.32, #POS                        0.19, 0.23 #INT                        )) Theta_CESD_f <- diag(c(0.45, 0.37, 0.39, 0.40, 0.57, 0.51, 0.37, #SOM                        0.29, 0.13, 0.09, 0.14, 0.29, 0.27, 0.24, #DEP                        0.72, 0.81, 0.32, 0.32, #POS                        0.19, 0.08 #INT                        ))  nu_CESD_r <- as.matrix(c(nu_SOM_r, nu_DEP_r, nu_POS_r, nu_INT_r)) nu_CESD_f <- as.matrix(c(nu_SOM_f, nu_DEP_f, nu_POS_f, nu_INT_f))  # From Miller et al. (1997) The Factor Structure of the CES-D in Two Surveys # of Elderly Mexican Americans p.S264; the correlation matrix of latent variables # based on the Hertzog et al. (1990) model. corr_CESD <- matrix(c(1, .93, .58, .85,                       .93, 1, .64, .88,                       .58, .64, 1, .55,                       .85, .88, .55, 1),                     nrow = 4, ncol = 4, byrow = TRUE) # Compute covariance matrix estimates for the focal and reference groups. S_f <- diag(sqrt(psi_CESD_f)) S_r <- diag(sqrt(psi_CESD_r)) psi_CESD_f <- S_f %*% corr_CESD %*% S_f psi_CESD_r <- S_r %*% corr_CESD %*% S_r   # The latent weights are specified to be proportional to the number of items # in each subscale.  CESD_full <- item_deletion_h(cut_z = 16,                              weights_item = c(rep(1, 20)),                              weights_latent = c(7, 7, 4, 2),                              alpha_r = alpha_CESD_r,                              alpha_f = alpha_CESD_f,                              psi_r = psi_CESD_r,                              psi_f = psi_CESD_f,                              lambda_r = lambda_CESD_r,                              lambda_f = lambda_CESD_f,                              nu_r = nu_CESD_r,                              nu_f = nu_CESD_f,                              Theta_r = Theta_CESD_r,                              Theta_f = Theta_CESD_f,                              plot_contour = FALSE,                              n_dim = 4,                              n_i_per_dim = c(7, 7, 4, 2),                              pmix_ref = pmix_CESD_r) CESD_full #> *********************************************************************** #> AGGREGATE CLASSIFICATION ACCURACY INDICES (CAI*) #> *********************************************************************** #> Aggregate CAI under PFI computed for item subsets: #>       PS*   SR*   SE*   SP* #> full 0.37 0.887 0.887 0.934 #> |4   0.37 0.883 0.883 0.931 #> |9   0.37 0.884 0.884 0.932 #> |10  0.37 0.887 0.887 0.934 #> |11  0.37 0.886 0.886 0.933 #> |15  0.37 0.886 0.886 0.933 #> |20  0.37 0.885 0.885 0.933 #>  #> Impact of deleting an item on aggregate CAI under PFI: #>     h(PS*) h(SR*) h(SE*) h(SP*) #> |4       0  0.014  0.014  0.011 #> |9       0  0.010  0.010  0.007 #> |10      0  0.002  0.002  0.002 #> |11      0  0.005  0.005  0.003 #> |15      0  0.006  0.006  0.004 #> |20      0  0.006  0.006  0.005 #>  #> *********************************************************************** #> Adverse Impact (AI) ratio for item subsets by  #>                invariance condition: #> *********************************************************************** #>      AI_SFI AI_PFI #> full      1  0.908 #> |4        1  0.908 #> |9        1  0.904 #> |10       1  0.930 #> |11       1  0.905 #> |15       1  0.977 #> |20       1  0.908 #>  #> *********************************************************************** #> COMPARING CAI FOR REFERENCE AND (EXPECTED) FOCAL #>                GROUPS #> *********************************************************************** #> Discrepancy between CAI of reference vs. Efocal groups under PFI: #>         h(PS)  h(SR) h(SE)  h(SP) #> r-Ef    0.085 -0.157 0.141 -0.164 #> r-Ef|4  0.085 -0.152 0.139 -0.160 #> r-Ef|9  0.089 -0.160 0.147 -0.168 #> r-Ef|10 0.064 -0.120 0.104 -0.126 #> r-Ef|11 0.088 -0.159 0.146 -0.167 #> r-Ef|15 0.021 -0.047 0.026 -0.048 #> r-Ef|20 0.084 -0.151 0.142 -0.158 #> ----------------------------------------------------------------------- #> Impact of deleting an item on the discrepancy between #>                CAI of #> reference vs. Efocal groups under PFI: #>         Δh(PS) Δh(SR) Δh(SE) Δh(SP) #> r-Ef|4   0.000  0.005  0.003  0.004 #> r-Ef|9  -0.004 -0.003 -0.006 -0.004 #> r-Ef|10  0.021  0.037  0.037  0.038 #> r-Ef|11 -0.003 -0.002 -0.005 -0.003 #> r-Ef|15  0.064  0.110  0.116  0.116 #> r-Ef|20  0.000  0.006 -0.001  0.006 CESD_full$PartInv$partial$outputlist$full #> Partial invariance results: #>  #> Proportion selected:  0.37  #> Cutpoint on the latent scale (xi):  1.053  #> Cutpoint on the observed scale (Z):  16  #> Adverse impact ratio (reference group: 'Reference'): #>  Focal #>  0.908 #>  #> Classification Accuracy Indices: #>                     Reference Focal E_R(Focal) #> True Positive           0.412 0.112      0.391 #> False Positive          0.045 0.032      0.024 #> True Negative           0.500 0.817      0.522 #> False Negative          0.043 0.039      0.063 #> Proportion Selected     0.457 0.144      0.415 #> Success Ratio           0.901 0.779      0.942 #> Sensitivity             0.906 0.743      0.861 #> Specificity             0.917 0.963      0.956 #>  #>  #> Strict invariance results: #>  #> Proportion selected:  0.369  #> Cutpoint on the latent scale (xi):  1.059  #> Cutpoint on the observed scale (Z):  16  #>  #> Classification Accuracy Indices: #>                     Reference Focal #> True Positive           0.406 0.121 #> False Positive          0.039 0.052 #> True Negative           0.507 0.798 #> False Negative          0.048 0.029 #> Proportion Selected     0.445 0.173 #> Success Ratio           0.913 0.701 #> Sensitivity             0.895 0.807 #> Specificity             0.929 0.939 CESD_full$PartInv$partial$outputlist$`|15` #> Partial invariance results: #>  #> Proportion selected:  0.37  #> Cutpoint on the latent scale (xi):  1.053  #> Cutpoint on the observed scale (Z):  15.95  #> Adverse impact ratio (reference group: 'Reference'): #>  Focal #>  0.977 #>  #> Classification Accuracy Indices: #>                     Reference Focal E_R(Focal) #> True Positive           0.407 0.121      0.404 #> False Positive          0.041 0.046      0.034 #> True Negative           0.505 0.803      0.511 #> False Negative          0.047 0.029      0.051 #> Proportion Selected     0.448 0.168      0.438 #> Success Ratio           0.909 0.723      0.922 #> Sensitivity             0.896 0.805      0.888 #> Specificity             0.925 0.945      0.937 #>  #>  #> Strict invariance results: #>  #> Proportion selected:  0.37  #> Cutpoint on the latent scale (xi):  1.053  #> Cutpoint on the observed scale (Z):  15.955  #>  #> Classification Accuracy Indices: #>                     Reference Focal #> True Positive           0.406 0.123 #> False Positive          0.039 0.053 #> True Negative           0.507 0.796 #> False Negative          0.048 0.028 #> Proportion Selected     0.445 0.176 #> Success Ratio           0.913 0.699 #> Sensitivity             0.894 0.815 #> Specificity             0.929 0.938 CESD_full_with_cutoff <- item_deletion_h(cut_z = 16,                                          weights_item = c(rep(1, 20)),                                          weights_latent = c(7, 7, 4, 2),                                          alpha_r = alpha_CESD_r,                                          alpha_f = alpha_CESD_f,                                          psi_r = psi_CESD_r,                                          psi_f = psi_CESD_f,                                          lambda_r = lambda_CESD_r,                                          lambda_f = lambda_CESD_f,                                          nu_r = nu_CESD_r,                                          nu_f = nu_CESD_f,                                          Theta_r = Theta_CESD_r,                                          Theta_f = Theta_CESD_f,                                          plot_contour = FALSE,                                          n_dim = 4,                                          n_i_per_dim = c(7, 7, 4, 2),                                          pmix_ref = pmix_CESD_r,                                          delete_one_cutoff = 16/60*(60-3)) CESD_full_with_cutoff #> *********************************************************************** #> AGGREGATE CLASSIFICATION ACCURACY INDICES (CAI*) #> *********************************************************************** #> Aggregate CAI under PFI computed for item subsets: #>        PS*   SR*   SE*   SP* #> full 0.370 0.887 0.887 0.934 #> |4   0.396 0.887 0.887 0.926 #> |9   0.397 0.889 0.889 0.927 #> |10  0.400 0.892 0.892 0.928 #> |11  0.403 0.891 0.891 0.927 #> |15  0.396 0.890 0.890 0.928 #> |20  0.400 0.890 0.890 0.927 #>  #> Impact of deleting an item on aggregate CAI under PFI: #>     h(PS*) h(SR*) h(SE*) h(SP*) #> |4  -0.053  0.001  0.001  0.031 #> |9  -0.056 -0.004 -0.004  0.028 #> |10 -0.062 -0.013 -0.013  0.024 #> |11 -0.068 -0.012 -0.012  0.029 #> |15 -0.055 -0.009 -0.009  0.024 #> |20 -0.062 -0.009 -0.009  0.028 #>  #> *********************************************************************** #> Adverse Impact (AI) ratio for item subsets by  #>                invariance condition: #> *********************************************************************** #>      AI_SFI AI_PFI #> full      1  0.908 #> |4        1  0.913 #> |9        1  0.909 #> |10       1  0.934 #> |11       1  0.911 #> |15       1  0.979 #> |20       1  0.914 #>  #> *********************************************************************** #> COMPARING CAI FOR REFERENCE AND (EXPECTED) FOCAL #>                GROUPS #> *********************************************************************** #> Discrepancy between CAI of reference vs. Efocal groups under PFI: #>         h(PS)  h(SR) h(SE)  h(SP) #> r-Ef    0.085 -0.157 0.141 -0.164 #> r-Ef|4  0.085 -0.148 0.135 -0.164 #> r-Ef|9  0.089 -0.155 0.143 -0.172 #> r-Ef|10 0.064 -0.116 0.101 -0.129 #> r-Ef|11 0.088 -0.154 0.142 -0.172 #> r-Ef|15 0.020 -0.045 0.025 -0.049 #> r-Ef|20 0.084 -0.146 0.138 -0.163 #> ----------------------------------------------------------------------- #> Impact of deleting an item on the discrepancy between #>                CAI of #> reference vs. Efocal groups under PFI: #>         Δh(PS) Δh(SR) Δh(SE) Δh(SP) #> r-Ef|4   0.000  0.009  0.006  0.000 #> r-Ef|9  -0.004  0.002 -0.002 -0.008 #> r-Ef|10  0.021  0.041  0.040  0.035 #> r-Ef|11 -0.003  0.003  0.000 -0.008 #> r-Ef|15  0.064  0.112  0.116  0.115 #> r-Ef|20  0.000  0.011  0.003  0.001 CESD_full_drop15 <- item_deletion_h(                           cut_z = 16/60*(60-3),                           weights_item = c(rep(1,14), 0, rep(4/3, 3), 1, 1),                           weights_latent = c(7, 7, 3, 2),                           alpha_r = alpha_CESD_r,                           alpha_f = alpha_CESD_f,                           psi_r = psi_CESD_r,                           psi_f = psi_CESD_f,                           lambda_r = lambda_CESD_r,                           lambda_f = lambda_CESD_f,                           nu_r = nu_CESD_r,                           nu_f = nu_CESD_f,                           Theta_r = Theta_CESD_r,                           Theta_f = Theta_CESD_f,                           pmix_ref = pmix_CESD_r,                           plot_contour = FALSE,                           n_dim = 4,                           n_i_per_dim = c(7, 7, 3, 2)) CESD_full_drop15 #> *********************************************************************** #> AGGREGATE CLASSIFICATION ACCURACY INDICES (CAI*) #> *********************************************************************** #> Aggregate CAI under PFI computed for item subsets: #>        PS*   SR*   SE*   SP* #> full 0.396 0.886 0.886 0.925 #> |4   0.396 0.882 0.882 0.922 #> |9   0.396 0.883 0.883 0.923 #> |10  0.396 0.885 0.885 0.924 #> |11  0.396 0.885 0.885 0.924 #> |20  0.396 0.881 0.881 0.922 #>  #> Impact of deleting an item on aggregate CAI under PFI: #>     h(PS*) h(SR*) h(SE*) h(SP*) #> |4       0  0.013  0.013  0.011 #> |9       0  0.009  0.009  0.007 #> |10      0  0.004  0.004  0.003 #> |11      0  0.004  0.004  0.003 #> |20      0  0.016  0.016  0.012 #>  #> *********************************************************************** #> Adverse Impact (AI) ratio for item subsets by  #>                invariance condition: #> *********************************************************************** #>      AI_SFI AI_PFI #> full      1  0.979 #> |4        1  0.979 #> |9        1  0.975 #> |10       1  0.999 #> |11       1  0.975 #> |20       1  0.978 #>  #> *********************************************************************** #> COMPARING CAI FOR REFERENCE AND (EXPECTED) FOCAL #>                GROUPS #> *********************************************************************** #> Discrepancy between CAI of reference vs. Efocal groups under PFI: #>         h(PS)  h(SR)  h(SE)  h(SP) #> r-Ef    0.020 -0.044  0.025 -0.047 #> r-Ef|4  0.020 -0.041  0.024 -0.045 #> r-Ef|9  0.024 -0.048  0.031 -0.052 #> r-Ef|10 0.001 -0.011 -0.007 -0.011 #> r-Ef|11 0.024 -0.048  0.031 -0.052 #> r-Ef|20 0.021 -0.041  0.028 -0.046 #> ----------------------------------------------------------------------- #> Impact of deleting an item on the discrepancy between #>                CAI of #> reference vs. Efocal groups under PFI: #>         Δh(PS) Δh(SR) Δh(SE) Δh(SP) #> r-Ef|4   0.001  0.002  0.001  0.002 #> r-Ef|9  -0.003 -0.004 -0.006 -0.005 #> r-Ef|10  0.020  0.032  0.017  0.036 #> r-Ef|11 -0.003 -0.004 -0.006 -0.005 #> r-Ef|20 -0.001  0.002 -0.003  0.002 CESD_full_drop15$PartInv$partial$outputlist$full #> Partial invariance results: #>  #> Proportion selected:  0.396  #> Cutpoint on the latent scale (xi):  0.399  #> Cutpoint on the observed scale (Z):  15.2  #> Adverse impact ratio (reference group: 'Reference'): #>  Focal #>  0.979 #>  #> Classification Accuracy Indices: #>                     Reference Focal E_R(Focal) #> True Positive           0.433 0.141      0.429 #> False Positive          0.042 0.053      0.036 #> True Negative           0.476 0.772      0.482 #> False Negative          0.050 0.034      0.053 #> Proportion Selected     0.475 0.194      0.465 #> Success Ratio           0.911 0.728      0.923 #> Sensitivity             0.897 0.808      0.889 #> Specificity             0.918 0.936      0.931 #>  #>  #> Strict invariance results: #>  #> Proportion selected:  0.397  #> Cutpoint on the latent scale (xi):  0.391  #> Cutpoint on the observed scale (Z):  15.2  #>  #> Classification Accuracy Indices: #>                     Reference Focal #> True Positive           0.432 0.143 #> False Positive          0.040 0.060 #> True Negative           0.477 0.765 #> False Negative          0.051 0.032 #> Proportion Selected     0.472 0.203 #> Success Ratio           0.915 0.706 #> Sensitivity             0.895 0.817 #> Specificity             0.922 0.928 CESD_full_drop15$PartInv$partial$outputlist$`|10` #> Partial invariance results: #>  #> Proportion selected:  0.396  #> Cutpoint on the latent scale (xi):  0.399  #> Cutpoint on the observed scale (Z):  15.238  #> Adverse impact ratio (reference group: 'Reference'): #>  Focal #>  0.999 #>  #> Classification Accuracy Indices: #>                     Reference Focal E_R(Focal) #> True Positive           0.431 0.143      0.432 #> False Positive          0.041 0.058      0.039 #> True Negative           0.477 0.767      0.478 #> False Negative          0.051 0.032      0.050 #> Proportion Selected     0.472 0.201      0.471 #> Success Ratio           0.914 0.711      0.917 #> Sensitivity             0.894 0.820      0.896 #> Specificity             0.921 0.930      0.924 #>  #>  #> Strict invariance results: #>  #> Proportion selected:  0.396  #> Cutpoint on the latent scale (xi):  0.399  #> Cutpoint on the observed scale (Z):  15.244  #>  #> Classification Accuracy Indices: #>                     Reference Focal #> True Positive           0.431 0.143 #> False Positive          0.040 0.060 #> True Negative           0.477 0.766 #> False Negative          0.051 0.032 #> Proportion Selected     0.472 0.202 #> Success Ratio           0.915 0.705 #> Sensitivity             0.894 0.816 #> Specificity             0.922 0.928"},{"path":"https://mmm-usc.github.io/unbiasr/articles/item-deletion-examples.html","id":"ces-d-somatic-complaints-factor","dir":"Articles","previous_headings":"Illustrative Example: CES-D","what":"CES-D Somatic Complaints Factor","title":"Applied examples of item deletion statistics","text":"first table illustrates removing item 4 Somatic Complaints subscale leads decreases aggregate SR, aggregate SE, aggregate SP, suggesting worse overall performance item dropped. third table shows deletion item 4 brings AI ratio already-high \\(0.998\\) \\(1\\). Similarly, removing item brings already small difference reference Efocal groups (ranging \\(-0.003\\) \\(0.003\\)) \\(0\\) small effect size \\(0.002\\) \\(0.003\\). findings suggest removing fourth item harm lead negligible improvement CAI, therefore full item set retained.","code":"# Items: bothered, appetite, mind, effort, sleep, talk, get going CESD_som <- item_deletion_h(cut_z = 16/60*7*3,                             weights_item = c(rep(1,7)),                              weights_latent = 1,                                alpha_r = alpha_SOM_r,                             alpha_f = alpha_SOM_f,                             psi_r = psi_SOM_r,                             psi_f = psi_SOM_f,                             lambda_r = lambda_SOM_r,                             lambda_f = lambda_SOM_f,                             nu_r = nu_SOM_r,                             nu_f = nu_SOM_f,                             Theta_r = Theta_SOM_r,                              Theta_f = Theta_SOM_f,                             pmix_ref = pmix_CESD_r,                             plot_contour = FALSE,                             n_dim = 1)                                CESD_som #> *********************************************************************** #> AGGREGATE CLASSIFICATION ACCURACY INDICES (CAI*) #> *********************************************************************** #> Aggregate CAI under PFI computed for item subsets: #>        PS*   SR*   SE*   SP* #> full 0.388 0.825 0.825 0.889 #> |4   0.388 0.807 0.807 0.878 #>  #> Impact of deleting an item on aggregate CAI under PFI: #>    h(PS*) h(SR*) h(SE*) h(SP*) #> |4      0  0.045  0.045  0.035 #>  #> *********************************************************************** #> Adverse Impact (AI) ratio for item subsets by  #>                invariance condition: #> *********************************************************************** #>      AI_SFI AI_PFI #> full      1  0.998 #> |4        1  1.000 #>  #> *********************************************************************** #> COMPARING CAI FOR REFERENCE AND (EXPECTED) FOCAL #>                GROUPS #> *********************************************************************** #> Discrepancy between CAI of reference vs. Efocal groups under PFI: #>        h(PS)  h(SR) h(SE)  h(SP) #> r-Ef   0.002 -0.002 0.003 -0.003 #> r-Ef|4 0.000  0.000 0.000  0.000 #> ----------------------------------------------------------------------- #> Impact of deleting an item on the discrepancy between #>                CAI of #> reference vs. Efocal groups under PFI: #>        Δh(PS) Δh(SR) Δh(SE) Δh(SP) #> r-Ef|4  0.002  0.002  0.003  0.003"},{"path":"https://mmm-usc.github.io/unbiasr/articles/item-deletion-examples.html","id":"ces-d-depressive-affect-factor","dir":"Articles","previous_headings":"Illustrative Example: CES-D","what":"CES-D Depressive Affect Factor","title":"Applied examples of item deletion statistics","text":"item_deletion_h determined items 2, 3, 4 contain level bias. see first table \\(\\overline{\\text{SP}}\\) around \\(0.940\\) item deletion scenarios \\(\\overline{\\text{SR}}\\) \\(\\overline{\\text{SE}}\\) slightly lower around \\(0.815\\) \\(830\\), suggesting Depressive Affect subscale best selecting individuals selected. see aggregate SE, aggregate SR, aggregate SP full item set higher item subsets, suggesting removal biased item likely improve aggregate CAI. \\(h\\) values second table range \\(0.010\\) \\(0.045\\), showing impact removing item quite small. AI ratio table shows removing third item increases AI \\(0.920\\) \\(0.993\\), bias fully eliminated \\(AI^{|3}<1\\). removal either item 2 item 4 increases discrepancy reference Efocal groups. second--last table illustrates removal item 3 brings \\(h^{\\text{r-Ef}}\\text{CAI}\\) closer 0, indicating improvement minimal-small effect size shown final table. Removing item harms CAI. Given lack agreement indices whether deletion item improves harms performance small effect size potential improvement, may best retain items choose alternative method item deletion subscale.","code":"# Items: blues, depressed, failure, fearful, lonely, crying, sad CESD_dep <- item_deletion_h(cut_z = 16/60*7*3,                             weights_item = c(rep(1,7)),                             weights_latent = 1,                               alpha_r = alpha_DEP_r,                             alpha_f = alpha_DEP_f,                             psi_r = psi_DEP_r,                             psi_f = psi_DEP_f,                             lambda_r = lambda_DEP_r,                             lambda_f = lambda_DEP_f,                             nu_r = nu_DEP_r,                             nu_f = nu_DEP_f,                             Theta_r = Theta_DEP_r,                              Theta_f = Theta_DEP_f,                             pmix_ref = pmix_CESD_r,                               plot_contour = FALSE,                             n_dim = 1) CESD_dep #> *********************************************************************** #> AGGREGATE CLASSIFICATION ACCURACY INDICES (CAI*) #> *********************************************************************** #> Aggregate CAI under PFI computed for item subsets: #>       PS*   SR*   SE*   SP* #> full 0.25 0.831 0.831 0.943 #> |2   0.25 0.814 0.814 0.938 #> |3   0.25 0.823 0.823 0.941 #> |4   0.25 0.820 0.820 0.940 #>  #> Impact of deleting an item on aggregate CAI under PFI: #>    h(PS*) h(SR*) h(SE*) h(SP*) #> |2      0  0.044  0.044  0.024 #> |3      0  0.020  0.020  0.011 #> |4      0  0.027  0.027  0.015 #>  #> *********************************************************************** #> Adverse Impact (AI) ratio for item subsets by  #>                invariance condition: #> *********************************************************************** #>      AI_SFI AI_PFI #> full      1  0.920 #> |2        1  0.907 #> |3        1  0.993 #> |4        1  0.910 #>  #> *********************************************************************** #> COMPARING CAI FOR REFERENCE AND (EXPECTED) FOCAL #>                GROUPS #> *********************************************************************** #> Discrepancy between CAI of reference vs. Efocal groups under PFI: #>        h(PS)  h(SR)  h(SE)  h(SP) #> r-Ef   0.056 -0.167  0.047 -0.130 #> r-Ef|2 0.065 -0.165  0.067 -0.133 #> r-Ef|3 0.004 -0.052 -0.033 -0.036 #> r-Ef|4 0.063 -0.164  0.065 -0.131 #> ----------------------------------------------------------------------- #> Impact of deleting an item on the discrepancy between #>                CAI of #> reference vs. Efocal groups under PFI: #>        Δh(PS) Δh(SR) Δh(SE) Δh(SP) #> r-Ef|2 -0.009  0.002 -0.020 -0.003 #> r-Ef|3  0.052  0.115  0.014  0.094 #> r-Ef|4 -0.007  0.003 -0.018  0.000"},{"path":"https://mmm-usc.github.io/unbiasr/articles/item-deletion-examples.html","id":"ces-d-positive-affect-factor","dir":"Articles","previous_headings":"Illustrative Example: CES-D","what":"CES-D Positive Affect Factor","title":"Applied examples of item deletion statistics","text":"biased item Positive Affect subscale item 1. see first output table deleting first item increases \\(\\overline{\\text{SR}}\\) \\(\\overline{\\text{SE}}\\) \\(0.883\\) \\(0.894\\), \\(\\overline{\\text{SP}}\\) \\(0.752\\) \\(0.777\\). second output table shows \\(h^{|1}\\overline{\\text{SR}}=h^{|1}\\overline{\\text{SE}}=-0.037\\) \\(h^{|1}\\overline{\\text{SP}}=-0.059\\), suggests improvement three \\(\\text{CAI}\\) small effect size \\((h < .20)\\). AI ratio full item set used \\(0.87\\). Removing first item achieves AI ratio \\(1\\), suggesting proportion selected reference group equal selected focal group focal reference groups followed reference group’s latent score distribution (.e., matched true (lack ) positive affect). finding shows removing first item eliminates measurement bias, replicated next table comparing \\(\\text{CAI}_R\\) \\(\\text{CAI}_{Ef}\\) \\(h^{\\text{r-Ef}}\\text{SR}^{|1}=h^{\\text{r-Ef}}\\text{SE}^{|1}=h^{\\text{r-Ef}}\\text{SP}^{|1}=0\\). Put words, item 1 removed, PS, SR, SE, SP reference group equal expected PS, SR, SE, SP focal group. final table shows effect size removing first item difference reference group’s CAI focal group’s expected CAI largest SE \\(\\Delta^{|1} h^{\\text{r-Ef}}\\text{SE}=0.223\\) SR \\(\\Delta^{|1} h^{\\text{r-Ef}}\\text{SP}=0.368\\), corresponding small-medium effect sizes. Taken together, improvements lack decreases CAI suggests researcher may drop item barring domain-specific reasons .","code":"# Items: good (biased), hopeful, happy, enjoyed CESD_pos <- item_deletion_h(cut_z = 16/60*12,                              weights_item = c(rep(1,4)),                              weights_latent = 1,                             alpha_r = alpha_POS_r,                             alpha_f = alpha_POS_f,                             psi_r = psi_POS_r,                             psi_f = psi_POS_f,                             lambda_r = lambda_POS_r,                             lambda_f = lambda_POS_f,                             nu_r = nu_POS_r,                             nu_f = nu_POS_f,                             Theta_r = Theta_POS_r,                              Theta_f = Theta_POS_f,                             pmix_ref = pmix_CESD_r,                              plot_contour = FALSE,                             user_specified_items = c(1:4)) CESD_pos #> *********************************************************************** #> AGGREGATE CLASSIFICATION ACCURACY INDICES (CAI*) #> *********************************************************************** #> Aggregate CAI under PFI computed for item subsets: #>        PS*   SR*   SE*   SP* #> full 0.679 0.883 0.883 0.752 #> |1   0.679 0.894 0.894 0.777 #> |2   0.679 0.876 0.876 0.738 #> |3   0.679 0.852 0.852 0.688 #> |4   0.679 0.853 0.853 0.689 #>  #> Impact of deleting an item on aggregate CAI under PFI: #>    h(PS*) h(SR*) h(SE*) h(SP*) #> |1      0 -0.037 -0.037 -0.059 #> |2      0  0.020  0.020  0.032 #> |3      0  0.089  0.089  0.142 #> |4      0  0.089  0.089  0.141 #>  #> *********************************************************************** #> Adverse Impact (AI) ratio for item subsets by  #>                invariance condition: #> *********************************************************************** #>      AI_SFI AI_PFI #> full      1  0.870 #> |1        1  1.000 #> |2        1  0.837 #> |3        1  0.830 #> |4        1  0.831 #>  #> *********************************************************************** #> COMPARING CAI FOR REFERENCE AND (EXPECTED) FOCAL #>                GROUPS #> *********************************************************************** #> Discrepancy between CAI of reference vs. Efocal groups under PFI: #>        h(PS)  h(SR) h(SE)  h(SP) #> r-Ef   0.208 -0.175 0.223 -0.368 #> r-Ef|1 0.000  0.000 0.000  0.000 #> r-Ef|2 0.263 -0.222 0.273 -0.468 #> r-Ef|3 0.272 -0.184 0.274 -0.431 #> r-Ef|4 0.272 -0.184 0.274 -0.431 #> ----------------------------------------------------------------------- #> Impact of deleting an item on the discrepancy between #>                CAI of #> reference vs. Efocal groups under PFI: #>        Δh(PS) Δh(SR) Δh(SE) Δh(SP) #> r-Ef|1  0.208  0.175  0.223  0.368 #> r-Ef|2 -0.055 -0.047 -0.050 -0.100 #> r-Ef|3 -0.064 -0.009 -0.051 -0.063 #> r-Ef|4 -0.064 -0.010 -0.051 -0.063"},{"path":"https://mmm-usc.github.io/unbiasr/articles/item-deletion-examples.html","id":"ces-d-interpersonal-problems-factor","dir":"Articles","previous_headings":"Illustrative Example: CES-D","what":"CES-D Interpersonal Problems Factor","title":"Applied examples of item deletion statistics","text":"Removing second item 2-item subscale leads lower \\(\\overline{\\text{CAI}}\\), effect size decrease \\(h^{|2} \\overline{\\text{SR}}= h^{|2}\\overline{\\text{SE}}=0.173\\), corresponds worsening performance small effect size. adverse impact ratio goes \\(1\\) \\(0.966\\) \\(h^{\\text{r-Ef}}\\text{CAI}^{|2}=0\\) indices. effect size improvement discrepancy reference Efocal groups SR item 2 deleted \\(\\Delta^{|2} h^{\\text{r-Ef}}\\text{SR}=0.132\\), \\(\\Delta^{|2} h^{\\text{r-Ef}}\\text{SE}=0.062\\), \\(\\Delta^{|2} h^{\\text{r-Ef}}\\text{SE}=0.086\\). Given conflicting findings fact subscale two items, best retain items subscale used make classification decisions. Now illustrate use user_specified_items: Specifying plot_contour = TRUE:  Using summary() function:","code":"# Items: unfriendly, dislike CESD_int <- item_deletion_h(cut_z = 16/60*2*3,                             weights_item = c(rep(1,2)),                             weights_latent = 1,                              alpha_r = alpha_INT_r,                             alpha_f = alpha_INT_f,                             psi_r = psi_INT_r,                             psi_f = psi_INT_f,                             lambda_r = lambda_INT_r,                             lambda_f = lambda_INT_f,                             nu_r = nu_INT_r,                             nu_f = nu_INT_f,                             Theta_r = Theta_INT_r,                              Theta_f = Theta_INT_f,                             pmix_ref = pmix_CESD_r,                             plot_contour = FALSE,                             n_dim = 1) CESD_int #> *********************************************************************** #> AGGREGATE CLASSIFICATION ACCURACY INDICES (CAI*) #> *********************************************************************** #> Aggregate CAI under PFI computed for item subsets: #>        PS*   SR*   SE*   SP* #> full 0.206 0.742 0.742 0.933 #> |2   0.206 0.663 0.663 0.913 #>  #> Impact of deleting an item on aggregate CAI under PFI: #>    h(PS*) h(SR*) h(SE*) h(SP*) #> |2      0  0.173  0.173  0.077 #>  #> *********************************************************************** #> Adverse Impact (AI) ratio for item subsets by  #>                invariance condition: #> *********************************************************************** #>      AI_SFI AI_PFI #> full      1  0.966 #> |2        1  1.000 #>  #> *********************************************************************** #> COMPARING CAI FOR REFERENCE AND (EXPECTED) FOCAL #>                GROUPS #> *********************************************************************** #> Discrepancy between CAI of reference vs. Efocal groups under PFI: #>        h(PS)  h(SR)  h(SE)  h(SP) #> r-Ef   0.021 -0.132 -0.062 -0.086 #> r-Ef|2 0.000  0.000  0.000  0.000 #> ----------------------------------------------------------------------- #> Impact of deleting an item on the discrepancy between #>                CAI of #> reference vs. Efocal groups under PFI: #>        Δh(PS) Δh(SR) Δh(SE) Δh(SP) #> r-Ef|2  0.021  0.132  0.062  0.086 CESD_pos <- item_deletion_h(cut_z = 16/60*12,                              weights_item = c(rep(1, 4)),                              weights_latent = 1,                             alpha_r = alpha_POS_r,                             alpha_f = alpha_POS_f,                             psi_r = psi_POS_r,                             psi_f = psi_POS_f,                             lambda_r = lambda_POS_r,                             lambda_f = lambda_POS_f,                             nu_r = nu_POS_r,                             nu_f = nu_POS_f,                             Theta_r = Theta_POS_r,                              Theta_f = Theta_POS_f,                             pmix_ref = pmix_CESD_r,                              plot_contour = FALSE,                             user_specified_items = c(1:3)) CESD_pos #> *********************************************************************** #> AGGREGATE CLASSIFICATION ACCURACY INDICES (CAI*) #> *********************************************************************** #> Aggregate CAI under PFI computed for item subsets: #>        PS*   SR*   SE*   SP* #> full 0.679 0.883 0.883 0.752 #> |1   0.679 0.894 0.894 0.777 #> |2   0.679 0.876 0.876 0.738 #> |3   0.679 0.852 0.852 0.688 #>  #> Impact of deleting an item on aggregate CAI under PFI: #>    h(PS*) h(SR*) h(SE*) h(SP*) #> |1      0 -0.037 -0.037 -0.059 #> |2      0  0.020  0.020  0.032 #> |3      0  0.089  0.089  0.142 #>  #> *********************************************************************** #> Adverse Impact (AI) ratio for item subsets by  #>                invariance condition: #> *********************************************************************** #>      AI_SFI AI_PFI #> full      1  0.870 #> |1        1  1.000 #> |2        1  0.837 #> |3        1  0.830 #>  #> *********************************************************************** #> COMPARING CAI FOR REFERENCE AND (EXPECTED) FOCAL #>                GROUPS #> *********************************************************************** #> Discrepancy between CAI of reference vs. Efocal groups under PFI: #>        h(PS)  h(SR) h(SE)  h(SP) #> r-Ef   0.208 -0.175 0.223 -0.368 #> r-Ef|1 0.000  0.000 0.000  0.000 #> r-Ef|2 0.263 -0.222 0.273 -0.468 #> r-Ef|3 0.272 -0.184 0.274 -0.431 #> ----------------------------------------------------------------------- #> Impact of deleting an item on the discrepancy between #>                CAI of #> reference vs. Efocal groups under PFI: #>        Δh(PS) Δh(SR) Δh(SE) Δh(SP) #> r-Ef|1  0.208  0.175  0.223  0.368 #> r-Ef|2 -0.055 -0.047 -0.050 -0.100 #> r-Ef|3 -0.064 -0.009 -0.051 -0.063 CESD_pos <- item_deletion_h(cut_z = 16/60*12,                              weights_item = c(rep(1,4)),                              weights_latent = 1,                             alpha_r = alpha_POS_r,                             alpha_f = alpha_POS_f,                             psi_r = psi_POS_r,                             psi_f = psi_POS_f,                             lambda_r = lambda_POS_r,                             lambda_f = lambda_POS_f,                             nu_r = nu_POS_r,                             nu_f = nu_POS_f,                             Theta_r = Theta_POS_r,                              Theta_f = Theta_POS_f,                             pmix_ref = pmix_CESD_r,                              plot_contour = TRUE) CESD_pos <- item_deletion_h(cut_z = 16/60*12,                              weights_item = c(rep(1, 4)),                              weights_latent = 1,                             alpha_r = alpha_POS_r,                             alpha_f = alpha_POS_f,                             psi_r = psi_POS_r,                             psi_f = psi_POS_f,                             lambda_r = lambda_POS_r,                             lambda_f = lambda_POS_f,                             nu_r = nu_POS_r,                             nu_f = nu_POS_f,                             Theta_r = Theta_POS_r,                              Theta_f = Theta_POS_f,                             pmix_ref = pmix_CESD_r,                              plot_contour = FALSE) summary(CESD_pos) #> *********************************************************************** #> AGGREGATE CLASSIFICATION ACCURACY INDICES (CAI*) #> *********************************************************************** #> Aggregate CAI computed for item subsets: #>        PS*   SR*   SE*   SP* #> full 0.679 0.883 0.883 0.752 #> |1   0.679 0.894 0.894 0.777 #>  #> Impact of deleting an item on aggregate CAI: #>    h(PS*) h(SR*) h(SE*) h(SP*) #> |1      0 -0.037 -0.037 -0.059 #> ----------------------------------------------------------------------- #> Discrepancy between aggregate CAI under SFI vs. PFI: #>               #>            h(PS*) h(SR*) h(SE*) h(SP*) #> SFI, PFI    0.012  0.006  0.006 -0.005 #> SFI, PFI|1  0.012  0.005  0.005 -0.005 #>  #> Impact of deleting an item on the discrepancy between aggregate CAI  #>       under  #> SFI vs. PFI: #>            Δh(h(PS*)) Δh(h(SR*)) Δh(h(SE*)) Δh(h(SP*)) #> SFI, PFI|1          0      0.001      0.001     -0.001 #>  #> *********************************************************************** #> Adverse Impact (AI) ratio for item subsets by  #>              invariance condition: #> *********************************************************************** #>      AI_SFI AI_PFI #> full      1   0.87 #> |1        1   1.00 #>  #> *********************************************************************** #> COMPARING CAI FOR REFERENCE AND (EXPECTED) FOCAL  #>              GROUPS #> *********************************************************************** #> Discrepancy between CAI of reference vs. Efocal groups: #>        h(TP) h(FP)  h(TN)  h(FN) h(PS)  h(SR) h(SE)  h(SP) #> r-Ef   0.108 0.179 -0.106 -0.185 0.208 -0.175 0.223 -0.368 #> r-Ef|1 0.000 0.000  0.000  0.000 0.000  0.000 0.000  0.000 #> ----------------------------------------------------------------------- #> Impact of deleting an item on the discrepancy between  #>              CAI of reference  #> vs. Efocal groups: #>        Δh(TP) Δh(FP) Δh(TN) Δh(FN) Δh(PS) Δh(SR) Δh(SE) Δh(SP) #> r-Ef|1  0.108  0.179  0.106  0.185  0.208  0.175  0.223  0.368 #>  #> *********************************************************************** #> COMPARING CAI UNDER STRICT AND PARTIAL FACTORIAL #>              INVARIANCE #> *********************************************************************** #> Discrepancy between CAI under SFI vs. PFI for the reference group: #>             h(TP)  h(FP)  h(TN)  h(FN)  h(PS) h(SR)  h(SE)  h(SP) #> SFI, PFI   -0.019 -0.059  0.027  0.056 -0.056 0.058 -0.065  0.113 #> SFI, PFI|1  0.012 -0.002 -0.011 -0.002  0.012 0.005  0.005 -0.005 #>  #> Discrepancy between CAI under SFI vs. PFI for the focal group: #>            h(TP)  h(FP)  h(TN)  h(FN) h(PS)  h(SR) h(SE)  h(SP) #> SFI, PFI   0.092  0.145 -0.096 -0.130 0.171 -0.140 0.181 -0.250 #> SFI, PFI|1 0.014 -0.001 -0.013 -0.001 0.013  0.006 0.006 -0.006 #> ----------------------------------------------------------------------- #> Impact of deleting an item on the discrepancy between #>              CAI under SFI  #> vs. PFI for the reference group: #>            Δh(TP) Δh(FP) Δh(TN) Δh(FN) Δh(PS) Δh(SR) Δh(SE) Δh(SP) #> SFI, PFI|1  0.007  0.057  0.015  0.054  0.044  0.053  0.059  0.108 #>  #> Impact of deleting an item on the discrepancy between CAI under SFI  #>        #> vs. PFI for the focal group: #>            Δh(TP) Δh(FP) Δh(TN) Δh(FN) Δh(PS) Δh(SR) Δh(SE) Δh(SP) #> SFI, PFI|1  0.078  0.143  0.083  0.129  0.158  0.134  0.175  0.244 #>  #> *********************************************************************** #> CAI under SFI vs. PFI for the reference group #> *********************************************************************** #>  #> Reference group, full item set: #>                       SFI   PFI      h #> True Positive       0.641 0.650 -0.019 #> False Positive      0.072 0.088 -0.059 #> True Negative       0.209 0.199  0.027 #> False Negative      0.077 0.063  0.056 #> Proportion Selected 0.713 0.738 -0.056 #> Success Ratio       0.899 0.881  0.058 #> Sensitivity         0.893 0.912 -0.065 #> Specificity         0.744 0.693  0.113 #> ----------------------------------------------------------------------- #>  #> Reference group, if item 1 is dropped: #>                       SFI   PFI      h #> True Positive       0.649 0.643  0.012 #> False Positive      0.065 0.066 -0.002 #> True Negative       0.216 0.221 -0.011 #> False Negative      0.069 0.070 -0.002 #> Proportion Selected 0.714 0.709  0.012 #> Success Ratio       0.909 0.907  0.005 #> Sensitivity         0.904 0.902  0.005 #> Specificity         0.769 0.771 -0.005 #>  #> *********************************************************************** #> CAI under SFI vs. PFI for the focal group #> *********************************************************************** #>  #> Focal group, full item set: #>                       SFI   PFI      h #> True Positive       0.512 0.466  0.092 #> False Positive      0.097 0.059  0.145 #> True Negative       0.307 0.352 -0.096 #> False Negative      0.084 0.123 -0.130 #> Proportion Selected 0.609 0.525  0.171 #> Success Ratio       0.841 0.889 -0.140 #> Sensitivity         0.859 0.791  0.181 #> Specificity         0.760 0.858 -0.250 #> ----------------------------------------------------------------------- #>  #> Focal group, if item 1 is dropped: #>                       SFI   PFI      h #> True Positive       0.520 0.513  0.014 #> False Positive      0.087 0.087 -0.001 #> True Negative       0.317 0.323 -0.013 #> False Negative      0.076 0.076 -0.001 #> Proportion Selected 0.607 0.600  0.013 #> Success Ratio       0.857 0.854  0.006 #> Sensitivity         0.872 0.870  0.006 #> Specificity         0.785 0.787 -0.006 #>  #> *********************************************************************** #> PartInv() outputs under Strict Factorial Invariance (SFI) #> *********************************************************************** #>  #> Under SFI, full item set: #>  #> Partial invariance results: #>  #> Proportion selected:  0.684  #> Cutpoint on the latent scale (xi):  -0.205  #> Cutpoint on the observed scale (Z):  3.2  #> Adverse impact ratio (reference group: 'Reference'): #>  Focal #>      1 #>  #> Classification Accuracy Indices: #>                     Reference Focal E_R(Focal) #> True Positive           0.641 0.512      0.641 #> False Positive          0.072 0.097      0.072 #> True Negative           0.209 0.307      0.209 #> False Negative          0.077 0.084      0.077 #> Proportion Selected     0.713 0.609      0.713 #> Success Ratio           0.899 0.841      0.899 #> Sensitivity             0.893 0.859      0.893 #> Specificity             0.744 0.760      0.744 #> ----------------------------------------------------------------------- #>  #> Under SFI, if item 1 is dropped: #>  #> Partial invariance results: #>  #> Proportion selected:  0.684  #> Cutpoint on the latent scale (xi):  -0.205  #> Cutpoint on the observed scale (Z):  2.899  #> Adverse impact ratio (reference group: 'Reference'): #>  Focal #>      1 #>  #> Classification Accuracy Indices: #>                     Reference Focal E_R(Focal) #> True Positive           0.649 0.520      0.649 #> False Positive          0.065 0.087      0.065 #> True Negative           0.216 0.317      0.216 #> False Negative          0.069 0.076      0.069 #> Proportion Selected     0.714 0.607      0.714 #> Success Ratio           0.909 0.857      0.909 #> Sensitivity             0.904 0.872      0.904 #> Specificity             0.769 0.785      0.769 #>  #>  #> Strict invariance results: #>  #> Proportion selected:  0.684  #> Cutpoint on the latent scale (xi):  -0.205  #> Cutpoint on the observed scale (Z):  2.899  #>  #> Classification Accuracy Indices: #>                     Reference Focal #> True Positive           0.649 0.520 #> False Positive          0.065 0.087 #> True Negative           0.216 0.317 #> False Negative          0.069 0.076 #> Proportion Selected     0.714 0.607 #> Success Ratio           0.909 0.857 #> Sensitivity             0.904 0.872 #> Specificity             0.769 0.785 #>  #> *********************************************************************** #> PartInv() outputs under Partial Factorial Invariance (PFI) #> *********************************************************************** #>  #> Under PFI, full item set: #>  #> Partial invariance results: #>  #> Proportion selected:  0.679  #> Cutpoint on the latent scale (xi):  -0.199  #> Cutpoint on the observed scale (Z):  3.2  #> Adverse impact ratio (reference group: 'Reference'): #>  Focal #>   0.87 #>  #> Classification Accuracy Indices: #>                     Reference Focal E_R(Focal) #> True Positive           0.650 0.466      0.598 #> False Positive          0.088 0.059      0.044 #> True Negative           0.199 0.352      0.243 #> False Negative          0.063 0.123      0.115 #> Proportion Selected     0.738 0.525      0.642 #> Success Ratio           0.881 0.889      0.931 #> Sensitivity             0.912 0.791      0.839 #> Specificity             0.693 0.858      0.846 #>  #>  #> Strict invariance results: #>  #> Proportion selected:  0.684  #> Cutpoint on the latent scale (xi):  -0.205  #> Cutpoint on the observed scale (Z):  3.2  #>  #> Classification Accuracy Indices: #>                     Reference Focal #> True Positive           0.641 0.512 #> False Positive          0.072 0.097 #> True Negative           0.209 0.307 #> False Negative          0.077 0.084 #> Proportion Selected     0.713 0.609 #> Success Ratio           0.899 0.841 #> Sensitivity             0.893 0.859 #> Specificity             0.744 0.760 #> ----------------------------------------------------------------------- #>  #> Under PFI, if item 1 is dropped: #>  #> Partial invariance results: #>  #> Proportion selected:  0.679  #> Cutpoint on the latent scale (xi):  -0.199  #> Cutpoint on the observed scale (Z):  2.951  #> Adverse impact ratio (reference group: 'Reference'): #>  Focal #>      1 #>  #> Classification Accuracy Indices: #>                     Reference Focal E_R(Focal) #> True Positive           0.643 0.513      0.643 #> False Positive          0.066 0.087      0.066 #> True Negative           0.221 0.323      0.221 #> False Negative          0.070 0.076      0.070 #> Proportion Selected     0.709 0.600      0.709 #> Success Ratio           0.907 0.854      0.907 #> Sensitivity             0.902 0.870      0.902 #> Specificity             0.771 0.787      0.771 #>  #>  #> Strict invariance results: #>  #> Proportion selected:  0.679  #> Cutpoint on the latent scale (xi):  -0.199  #> Cutpoint on the observed scale (Z):  2.951  #>  #> Classification Accuracy Indices: #>                     Reference Focal #> True Positive           0.643 0.513 #> False Positive          0.066 0.087 #> True Negative           0.221 0.323 #> False Negative          0.070 0.076 #> Proportion Selected     0.709 0.600 #> Success Ratio           0.907 0.854 #> Sensitivity             0.902 0.870 #> Specificity             0.771 0.787"},{"path":"https://mmm-usc.github.io/unbiasr/authors.html","id":null,"dir":"","previous_headings":"","what":"Authors","title":"Authors and Citation","text":"Clay Cantrell. Author, maintainer. Hok Chio (Mark) Lai. Author. Yichi Zhang. Author. Meltem Ozcan. Author.","code":""},{"path":"https://mmm-usc.github.io/unbiasr/authors.html","id":"citation","dir":"","previous_headings":"","what":"Citation","title":"Authors and Citation","text":"Cantrell C, Lai H, Zhang Y, Ozcan M (2024). unbiasr: Multidimensional Classification Accuracy Analysis Framework. R package version 0.0.2, https://mmm-usc.github.io/unbiasr/.","code":"@Manual{,   title = {unbiasr: Multidimensional Classification Accuracy Analysis Framework},   author = {Clay Cantrell and Hok Chio (Mark) Lai and Yichi Zhang and Meltem Ozcan},   year = {2024},   note = {R package version 0.0.2},   url = {https://mmm-usc.github.io/unbiasr/}, }"},{"path":"https://mmm-usc.github.io/unbiasr/index.html","id":"unbiasr","dir":"","previous_headings":"","what":"Multidimensional Classification Accuracy Analysis Framework","title":"Multidimensional Classification Accuracy Analysis Framework","text":"MMM Lab@USC","code":""},{"path":"https://mmm-usc.github.io/unbiasr/index.html","id":"installation","dir":"","previous_headings":"","what":"Installation","title":"Multidimensional Classification Accuracy Analysis Framework","text":"can install development version unbiasr GitHub :","code":"# install.packages(\"remotes\") remotes::install_github(\"mmm-usc/unbiasr\")"},{"path":"https://mmm-usc.github.io/unbiasr/index.html","id":"example","dir":"","previous_headings":"","what":"Example","title":"Multidimensional Classification Accuracy Analysis Framework","text":"basic example shows solve common problem:","code":"library(unbiasr) ## Toy example from Millsap & Kwok (2004, doi: 10.1037/1082-989X.9.1.93) PartInv(     propsel = .25,     alpha_r = 0.5,     alpha_f = 0,     psi_r = 1,     lambda_r = c(.3, .5, .9, .7),     nu_r = c(.225, .025, .010, .240),     nu_f = c(.225, -.05, .240, -.025),     Theta_r = diag(.96, 4) ) #> Proportion selected:  0.25  #> Cutpoint on the latent scale (xi):  0.946  #> Cutpoint on the observed scale (Z):  3.182  #> AI ratio:  0.96  #>  #> Classification Accuracy Indices: #>                     Reference Focal E_R(Focal) #> True Positive           0.224 0.108      0.219 #> False Positive          0.092 0.076      0.085 #> True Negative           0.580 0.752      0.587 #> False Negative          0.103 0.064      0.109 #> Proportion Selected     0.316 0.184      0.304 #> Success Ratio           0.710 0.587      0.720 #> Sensitivity             0.684 0.627      0.667 #> Specificity             0.863 0.908      0.873"},{"path":"https://mmm-usc.github.io/unbiasr/index.html","id":"shiny-application","dir":"","previous_headings":"","what":"Shiny Application","title":"Multidimensional Classification Accuracy Analysis Framework","text":"Browser version: https://mmmlabusc.shinyapps.io/partinvshinyui/ call unbiasr::launch() R.","code":""},{"path":"https://mmm-usc.github.io/unbiasr/index.html","id":"references","dir":"","previous_headings":"","what":"References","title":"Multidimensional Classification Accuracy Analysis Framework","text":"Millsap, R. E., & Kwok, O.-M. (2004). Evaluating impact partial factorial invariance selection two populations. Psychological Methods, 9(1), 93–115. https://doi.org/10.1037/1082-989X.9.1.93 Lai, M. H. C., Kwok, O., Yoon, M., & Hsiao, Y.-Y. (2017). Understanding impact partial factorial invariance selection accuracy: R script. Structural Equation Modeling: Multidisciplinary Journal, 24(5), 783–799. https://doi.org/10.1080/10705511.2017.1318703 Lai, M. H. C., & Zhang, Y. (2022). Classification accuracy multidimensional tests: Quantifying impact noninvariance. Structural Equation Modeling: Multidisciplinary Journal. Advance online publication. https://doi.org/10.1080/10705511.2021.1977936 development package supported U.S. Army Research Institute Behavioral Social Sciences (ARI) Grant W911NF2010282. views, opinions, /findings contained report (paper) authors shall construed official Department Army position, policy, decision, unless designated documents.","code":""},{"path":"https://mmm-usc.github.io/unbiasr/reference/PartInv.html","id":null,"dir":"Reference","previous_headings":"","what":"Evaluating selection accuracy for two or more groups based on the MCAA Framework — PartInv","title":"Evaluating selection accuracy for two or more groups based on the MCAA Framework — PartInv","text":"PartInv, PartInvMulti_we evaluates partial measurement invariance using multidimensional classification accuracy analysis (Lai & Zhang, 2022), extension Millsap & Kwok's (2004) approach.","code":""},{"path":"https://mmm-usc.github.io/unbiasr/reference/PartInv.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Evaluating selection accuracy for two or more groups based on the MCAA Framework — PartInv","text":"","code":"PartInv(   propsel = NULL,   cut_z = NULL,   weights_item = NULL,   weights_latent = NULL,   alpha,   psi,   lambda,   theta,   nu,   pmix = 0.5,   pmix_ref = 0.5,   plot_contour = FALSE,   show_mi_result = FALSE,   labels = NULL,   kappa_r = NULL,   kappa_f = kappa_r,   alpha_r = NULL,   alpha_f = alpha_r,   phi_r = NULL,   phi_f = phi_r,   psi_r = NULL,   psi_f = psi_r,   lambda_r = NULL,   lambda_f = lambda_r,   tau_r = NULL,   tau_f = tau_r,   nu_r = NULL,   nu_f = nu_r,   Theta_r = NULL,   Theta_f = Theta_r,   ... )  PartInvMulti_we(...)"},{"path":"https://mmm-usc.github.io/unbiasr/reference/PartInv.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Evaluating selection accuracy for two or more groups based on the MCAA Framework — PartInv","text":"propsel Proportion selection. missing, computed using cut_z. cut_z Pre-specified cutoff score observed composite. argument ignored propsel input. weights_item vector item weights. weights_latent vector latent factor weights. alpha list length g containing 1 x d latent factor mean vectors g number groups d number latent dimensions. first element assumed belong reference group. psi list length g containing d x d latent factor variance-covariance matrices g number groups d number latent dimensions. first element assumed belong reference group. lambda list length g containing n x d factor loading matrices g number groups, d number latent dimensions, n number items scale. first element assumed belong reference group. theta list length g containing 1 x n vectors n x n matrices unique factor variances covariances, g number groups n number items scale. first element assumed belong reference group. nu list length g containing 1 x n measurement intercept vectors g number groups n number items scale. first element assumed belong reference group. pmix List length g containing mixing proportions group. NULL, defaults 1/g group (.e., populations equal size). plot_contour Logical; whether contour populations plotted; TRUE default. show_mi_result TRUE, perform selection accuracy analysis input parameters implied parameters based strict invariance model, common parameter values weighted averages input values using pmix. labels character vector g elements label reference focal groups plot, g number groups. provided, groups labeled automatically 'Reference' (first group) 'Focal_1' 'Focal_(g-1)', g number groups. alpha_r, alpha_f, nu_r, nu_f, Theta_r, Theta_f, psi_r, psi_f, lambda_r, lambda_f, phi_r, phi_f, tau_r, tau_f, kappa_r, kappa_f, pmix_ref Deprecated; included backward compatibility. comparing two groups, parameters '_r' suffix refer reference group parameters '_f' suffix refer focal group. ... arguments passed contour function.","code":""},{"path":"https://mmm-usc.github.io/unbiasr/reference/PartInv.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Evaluating selection accuracy for two or more groups based on the MCAA Framework — PartInv","text":"output list six elements plot plot_contour == TRUE: propsel Proportion selected. cutpt_xi Cut point latent scale (xi). cutpt_z Cut point observed scale (Z). summary 8 x (g + g - 1) table, columns representing reference g - 1 focal groups, expected results latent distribution g - 1 focal group match reference group. rows represent probabilities true positive (), false positive (B), true negative (C), false negative (D); proportion selected, success ratio, sensitivity, specificity. bivardata List length 5 containing 1 x g vectors latent observed means, standard deviations, covariances computed groups. ai_ratio list length g - 1 containing Adverse Impact (AI) ratio computed focal group. result less 80% may considered evidence adverse impact. show_mi_result = TRUE, returned list additional elements : propsel_mi Proportion selected strict invariance. cutpt_xi_mi Cut point latent scale (xi) strict invariance. cutpt_z_mi Cut point observed scale (Z) strict invariance. summary_mi 8 x (g + g - 1) table, columns representing reference g - 1 focal groups expected results latent distributions g - 1 focal groups match reference group, strict invariance. rows represent probabilities true positive (), false positive (B), true negative (C), false negative (D); proportion selected, success ratio, sensitivity, specificity. bivardata_mi List length 5 containing 1 x g vectors latent observed means, standard deviations, covariances computed group strict invariance.","code":""},{"path":"https://mmm-usc.github.io/unbiasr/reference/PartInv.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Evaluating selection accuracy for two or more groups based on the MCAA Framework — PartInv","text":"","code":"# Two groups, single dimension PartInv(propsel = .30,         weights_item = c(1, 1, 1, 1),         weights_latent = 1,         alpha = list(0, 0),         psi = list(1, 1),         lambda = list(c(1, 1, 1, 1), c(1, 1, 1, 1)),         nu = list(c(1, 1, 1, 2), c(1, 1, 1, 1)),         theta = list(diag(1, 4), diag(1, 4)),         labels = c(\"Female\", \"Male\"),         show_mi_result = TRUE) #> Partial invariance results: #>  #> Proportion selected:  0.3  #> Cutpoint on the latent scale (xi):  0.524  #> Cutpoint on the observed scale (Z):  6.86  #> Adverse impact ratio (reference group: 'Female'): #>   Male #>  0.771 #>  #> Classification Accuracy Indices: #>                     Female  Male E_R(Male) #> True Positive        0.252 0.217     0.217 #> False Positive       0.087 0.045     0.045 #> True Negative        0.613 0.655     0.655 #> False Negative       0.048 0.083     0.083 #> Proportion Selected  0.339 0.261     0.261 #> Success Ratio        0.743 0.829     0.829 #> Sensitivity          0.839 0.722     0.722 #> Specificity          0.876 0.936     0.936 #>  #>  #> Strict invariance results: #>  #> Proportion selected:  0.3  #> Cutpoint on the latent scale (xi):  0.524  #> Cutpoint on the observed scale (Z):  6.845  #>  #> Classification Accuracy Indices: #>                     Female  Male #> True Positive        0.236 0.236 #> False Positive       0.064 0.064 #> True Negative        0.636 0.636 #> False Negative       0.064 0.064 #> Proportion Selected  0.300 0.300 #> Success Ratio        0.786 0.786 #> Sensitivity          0.786 0.786 #> Specificity          0.908 0.908 # Two groups, two dimensions lambda_matrix <- matrix(0, nrow = 5, ncol = 2) lambda_matrix[1:2, 1] <- c(.322, .655) lambda_matrix[3:5, 2] <- c(.398, .745, .543) PartInv(propsel = .05,         weights_latent = c(0.5, 0.5),         alpha = list(c(0, 0), c(-0.3, 0.1)),         psi = list(matrix(c(1, 0.5, 0.5, 1), nrow = 2),                    matrix(c(1, 0.5, 0.5, 1), nrow = 2)),         lambda = list(lambda_matrix, lambda_matrix),         nu = list(c(.225, .25, .010, .30, .125),                   c(.225, -.05, .240, -.025, .125)),         theta = list(diag(1, 5), c(1, .95, .80, .75, 1)),         plot_contour = TRUE, show_mi_result = TRUE)   #> Partial invariance results: #>  #> Proportion selected:  0.05  #> Cutpoint on the latent scale (xi):  1.377  #> Cutpoint on the observed scale (Z):  5.925  #> Adverse impact ratio (reference group: 'Reference'): #>  Focal_1 #>    0.714 #>  #> Classification Accuracy Indices: #>                     Reference Focal_1 E_R(Focal_1) #> True Positive           0.024   0.017        0.021 #> False Positive          0.036   0.023        0.023 #> True Negative           0.908   0.933        0.921 #> False Negative          0.032   0.027        0.035 #> Proportion Selected     0.060   0.040        0.043 #> Success Ratio           0.404   0.426        0.475 #> Sensitivity             0.436   0.384        0.367 #> Specificity             0.962   0.976        0.976 #>  #>  #> Strict invariance results: #>  #> Proportion selected:  0.05  #> Cutpoint on the latent scale (xi):  1.377  #> Cutpoint on the observed scale (Z):  5.903  #>  #> Classification Accuracy Indices: #>                     Reference Focal_1 #> True Positive           0.023   0.019 #> False Positive          0.029   0.029 #> True Negative           0.915   0.927 #> False Negative          0.033   0.025 #> Proportion Selected     0.052   0.048 #> Success Ratio           0.436   0.388 #> Sensitivity             0.405   0.422 #> Specificity             0.969   0.969 # Multiple groups, multiple dimensions lambda_matrix <- matrix(0, nrow = 15, ncol = 1) lambda_matrix[1:15, 1] <- c(0.68, 0.79, -0.39, 0.74, 0.59, 0.46, 0.78, -0.30,                             0.59, 0.59, 0.64, 0.66, 0.59, 0.63, 0.64); nu_matrix <- nu_matrix1 <- nu_matrix2 <- nu_matrix3 <-   matrix(0, nrow = 15, ncol = 1) nu_matrix[1:15, 1] <- c(3.6, 3.1, 2.7, 2.9, 2.5, 2.1, 3.45, 2.62, 3.2, 2.84,                         3.51, 3.26, 2.45, 3.39, 2.47); nu_matrix1[1:15, 1] <- c(3.9, 3.1, 2.7, 2.9, 2.5, 2.1, 3.45, 2.62, 3.2, 2.84,                          3.51, 3.26, 2.45, 3.76, 2.81); nu_matrix2[1:15, 1] <- c(3.6, 3.1, 2.7, 2.9, 2.5, 2.1, 3.45, 2.62, 3.6, 3.18,                          3.51, 3.54, 2.45, 3.39, 2.81); nu_matrix3[1:15, 1] <- c(3.6, 3.1, 2.7, 2.6, 2.5, 2.1, 3.45, 2.62, 3.2, 2.84,                          3.51, 3.26, 2.45, 3.39, 2.81); theta_matrix <- c(0.35, 0.62, 0.83, 0.61, 0.81, 0.87, 0.39, 1.05, 0.84, 0.92,                   0.36, 0.66, 0.8, 0.66, 0.9); theta_matrix1 <- c(0.61, 0.62, 0.83, 0.61, 0.81, 0.5, 0.7, 1.05, 0.84, 0.92,                    0.61, 0.66, 0.8, 0.54, 0.9); theta_matrix2 <- c(0.61, 0.62, 0.826, 0.61, 0.81, 0.87, 0.5, 1.05, 0.84,                    0.92, 0.61, 0.66, 0.8, 0.66, 0.9); theta_matrix3 <- c(0.61, 0.62, 0.826, 0.61, 0.81, 0.5, 0.7, 1.05, 0.84, 0.92,                    0.61, 0.66, 0.8, 0.66, 0.9); PartInv(propsel = 0.25, pmix = c(1/4, 1/4, 1/4, 1/4),         alpha = list(0, -0.70, -1.05, -1.10), psi = list(1, 1.2, 1.29, 1.3),         nu = list(nu_matrix, nu_matrix1, nu_matrix2, nu_matrix3),         lambda = list(lambda_matrix, lambda_matrix, lambda_matrix,                       lambda_matrix),         theta = list(theta_matrix, theta_matrix1, theta_matrix2,                      theta_matrix3),         plot_contour = TRUE, show_mi_result = TRUE,         labels = c(\"Group 1\", \"Group 2\", \"Group 3\", \"Group 4\"),         custom_colors = c(\"salmon1\", \"lightgreen\", \"skyblue1\", \"pink\")         )   #> Partial invariance results: #>  #> Proportion selected:  0.25  #> Cutpoint on the latent scale (xi):  0.095  #> Cutpoint on the observed scale (Z):  45.754  #> Adverse impact ratio (reference group: 'Group 1'): #>  Group.2 Group.3 Group.4 #>    1.114   1.153   1.005 #>  #> Classification Accuracy Indices: #>                     Group 1 Group 2 Group 3 Group 4 E_R(Group 2) E_R(Group 3) #> True Positive         0.376   0.196   0.132   0.111        0.401        0.408 #> False Positive        0.045   0.057   0.053   0.030        0.068        0.078 #> True Negative         0.493   0.710   0.790   0.823        0.470        0.460 #> False Negative        0.086   0.038   0.024   0.036        0.061        0.054 #> Proportion Selected   0.421   0.252   0.185   0.141        0.469        0.486 #> Success Ratio         0.894   0.776   0.714   0.789        0.855        0.840 #> Sensitivity           0.814   0.837   0.844   0.757        0.867        0.882 #> Specificity           0.917   0.926   0.937   0.965        0.874        0.855 #>                     E_R(Group 4) #> True Positive              0.376 #> False Positive             0.047 #> True Negative              0.491 #> False Negative             0.086 #> Proportion Selected        0.423 #> Success Ratio              0.889 #> Sensitivity                0.814 #> Specificity                0.913 #>  #>  #> Strict invariance results: #>  #> Proportion selected:  0.25  #> Cutpoint on the latent scale (xi):  0.095  #> Cutpoint on the observed scale (Z):  45.806  #>  #> Classification Accuracy Indices: #>                     Group 1 Group 2 Group 3 Group 4 #> True Positive         0.390   0.189   0.125   0.117 #> False Positive        0.057   0.047   0.038   0.037 #> True Negative         0.481   0.719   0.805   0.816 #> False Negative        0.072   0.045   0.032   0.030 #> Proportion Selected   0.447   0.237   0.163   0.154 #> Success Ratio         0.872   0.800   0.766   0.760 #> Sensitivity           0.844   0.809   0.795   0.793 #> Specificity           0.894   0.938   0.955   0.957"},{"path":"https://mmm-usc.github.io/unbiasr/reference/PartInv_old.html","id":null,"dir":"Reference","previous_headings":"","what":"Evaluate partial measurement invariance using Millsap & Kwok's (2004) approach — PartInv_old","title":"Evaluate partial measurement invariance using Millsap & Kwok's (2004) approach — PartInv_old","text":"Evaluate partial measurement invariance using Millsap & Kwok's (2004) approach","code":""},{"path":"https://mmm-usc.github.io/unbiasr/reference/PartInv_old.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Evaluate partial measurement invariance using Millsap & Kwok's (2004) approach — PartInv_old","text":"","code":"PartInv_old(   propsel,   cut_z = NULL,   kappa_r,   kappa_f = kappa_r,   phi_r,   phi_f = phi_r,   lambda_r,   lambda_f = lambda_r,   Theta_r,   Theta_f = Theta_r,   tau_r,   tau_f = tau_r,   pmix_ref = 0.5,   plot_contour = TRUE,   labels = c(\"Reference group\", \"Focal group\"),   ... )"},{"path":"https://mmm-usc.github.io/unbiasr/reference/PartInv_old.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Evaluate partial measurement invariance using Millsap & Kwok's (2004) approach — PartInv_old","text":"propsel proportion selection. missing, computed using cut_z. cut_z prespecified cutoff score observed composite. argument ignored propsel input. kappa_r latent factor mean reference group. kappa_f (optional) latent factor mean focal group; input, set equal kappa_r. phi_r latent factor variance reference group. phi_f (optional) latent factor variance focal group; input, set equal phi_r. lambda_r vector factor loadings reference group. lambda_f (optional) vector factor loadings focal group; input, set equal lambda_r. Theta_r matrix unique factor variances covariances reference group. Theta_f (optional) matrix unique factor variances covariances focal group; input, set equal Theta_r. tau_r vector measurement intercepts reference group. tau_f (optional) vector measurement intercepts focal group; input, set equal tau_r. pmix_ref Proportion reference group; default 0.5 (.e., two populations equal size). plot_contour logical; whether contour two populations plotted; default TRUE. labels character vector two elements label reference focal group graph. ... arguments passed contour function.","code":""},{"path":"https://mmm-usc.github.io/unbiasr/reference/PartInv_old.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Evaluate partial measurement invariance using Millsap & Kwok's (2004) approach — PartInv_old","text":"list four elements plot plot_contour == TRUE. four elements propsel echo argument input cutpt_xi cut point latent scale (xi) cutpt_z cut point observed scale (Z) summary 8 x 2 table, columns representing reference focal groups, rows represent probabilities true positive (), false positive (B), true negative (C), false negative (D); proportion selected, success ratio, sensitivity, specificity.","code":""},{"path":"https://mmm-usc.github.io/unbiasr/reference/PartInv_old.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Evaluate partial measurement invariance using Millsap & Kwok's (2004) approach — PartInv_old","text":"","code":"PartInv(propsel = .25, kappa_r = 0.5, kappa_f = 0, phi_r = 1,         lambda_r = c(.3, .5, .9, .7), tau_r = c(.225, .025, .010, .240),         Theta_r = diag(.96, 4), labels = c(\"female\", \"male\")) #> Partial invariance results: #>  #> Proportion selected:  0.25  #> Cutpoint on the latent scale (xi):  0.946  #> Cutpoint on the observed scale (Z):  3.229  #> Adverse impact ratio (reference group: 'female'): #>  male #>     1 #>  #> Classification Accuracy Indices: #>                     female  male E_R(male) #> True Positive        0.222 0.110     0.222 #> False Positive       0.089 0.079     0.089 #> True Negative        0.583 0.748     0.583 #> False Negative       0.106 0.062     0.106 #> Proportion Selected  0.311 0.189     0.311 #> Success Ratio        0.714 0.580     0.714 #> Sensitivity          0.677 0.638     0.677 #> Specificity          0.868 0.904     0.868"},{"path":"https://mmm-usc.github.io/unbiasr/reference/acc_indices_h.html","id":null,"dir":"Reference","previous_headings":"","what":"Compute Cohen's h for the difference under strict vs. partial invariance for the reference and the focal group. — acc_indices_h","title":"Compute Cohen's h for the difference under strict vs. partial invariance for the reference and the focal group. — acc_indices_h","text":"acc_indices_h takes outputs PartInv() returns two restructured data frames classification accuracy indices reference focal groups strict invariance partial invariance conditions, corresponding h difference CAI two invariance conditions group.","code":""},{"path":"https://mmm-usc.github.io/unbiasr/reference/acc_indices_h.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Compute Cohen's h for the difference under strict vs. partial invariance for the reference and the focal group. — acc_indices_h","text":"","code":"acc_indices_h(strict_output, partial_output)"},{"path":"https://mmm-usc.github.io/unbiasr/reference/acc_indices_h.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Compute Cohen's h for the difference under strict vs. partial invariance for the reference and the focal group. — acc_indices_h","text":"strict_output Output PartInv() strict invariance. partial_output Output PartInv() partial invariance.","code":""},{"path":"https://mmm-usc.github.io/unbiasr/reference/acc_indices_h.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Compute Cohen's h for the difference under strict vs. partial invariance for the reference and the focal group. — acc_indices_h","text":"8 x 3 dataframe columns strict invariance, partial invariance, h.","code":""},{"path":"https://mmm-usc.github.io/unbiasr/reference/cohens_h.html","id":null,"dir":"Reference","previous_headings":"","what":"Compute Cohen's h effect size for the difference in two proportions. — cohens_h","title":"Compute Cohen's h effect size for the difference in two proportions. — cohens_h","text":"cohens_h computes Cohen's h (Cohen, 1988) difference two proportions using \\(h = 2arcsin(\\sqrt{p1}) - 2arcsin(\\sqrt{p2})\\).","code":""},{"path":"https://mmm-usc.github.io/unbiasr/reference/cohens_h.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Compute Cohen's h effect size for the difference in two proportions. — cohens_h","text":"","code":"cohens_h(p1, p2)"},{"path":"https://mmm-usc.github.io/unbiasr/reference/cohens_h.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Compute Cohen's h effect size for the difference in two proportions. — cohens_h","text":"p1 first proportion. p2 second proportion.","code":""},{"path":"https://mmm-usc.github.io/unbiasr/reference/cohens_h.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Compute Cohen's h effect size for the difference in two proportions. — cohens_h","text":"h computed Cohen's h value.","code":""},{"path":"https://mmm-usc.github.io/unbiasr/reference/cohens_h.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Compute Cohen's h effect size for the difference in two proportions. — cohens_h","text":"","code":"cohens_h(0.7, 0.75) #> [1] -0.1120819 cohens_h(0.3, 0.4) #> [1] -0.2101589"},{"path":"https://mmm-usc.github.io/unbiasr/reference/compute_cai.html","id":null,"dir":"Reference","previous_headings":"","what":"Compute summary statistics. — compute_cai","title":"Compute summary statistics. — compute_cai","text":"compute_cai computes classification accuracy indices.","code":""},{"path":"https://mmm-usc.github.io/unbiasr/reference/compute_cai.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Compute summary statistics. — compute_cai","text":"","code":"compute_cai(   weights_item,   weights_latent,   alpha,   psi,   lambda,   nu,   theta,   pmix,   propsel,   labels,   cut_z = NULL,   is_mi = FALSE )"},{"path":"https://mmm-usc.github.io/unbiasr/reference/compute_cai.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Compute summary statistics. — compute_cai","text":"weights_item vector item weights. weights_latent vector latent factor weights. alpha list length g containing 1 x d latent factor mean vectors g number groups d number latent dimensions. first element assumed belong reference group. psi list length g containing d x d latent factor variance-covariance matrices g number groups d number latent dimensions. first element assumed belong reference group. lambda list length g containing n x d factor loading matrices g number groups, d number latent dimensions, n number items scale. first element assumed belong reference group. nu list length g containing 1 x n measurement intercept vectors g number groups n number items scale. first element assumed belong reference group. theta list length g containing 1 x n vectors n x n matrices unique factor variances covariances, g number groups n number items scale. first element assumed belong reference group. pmix List length g containing mixing proportions group. propsel Proportion selection. missing, computed using cut_z. labels character vector g elements label reference focal groups plot, g number groups. cut_z Pre-specified cutoff score observed composite. argument ignored propsel input. is_mi Whether summary statistics computed strict vs. partial measurement invariance. FALSE default (partial).","code":""},{"path":"https://mmm-usc.github.io/unbiasr/reference/compute_cai.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Compute summary statistics. — compute_cai","text":"output list 5 elements: propsel Proportion selected. cutpt_xi Cut point latent variable. cutpt_z Cut point observed variable. summary Summary statistics. bivar_data mean, standard deviation, covariance latent observed variables group.","code":""},{"path":"https://mmm-usc.github.io/unbiasr/reference/contour_bvnorm.html","id":null,"dir":"Reference","previous_headings":"","what":"Plot contour for a bivariate normal distribution — contour_bvnorm","title":"Plot contour for a bivariate normal distribution — contour_bvnorm","text":"Plot contour bivariate normal distribution","code":""},{"path":"https://mmm-usc.github.io/unbiasr/reference/contour_bvnorm.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Plot contour for a bivariate normal distribution — contour_bvnorm","text":"","code":"contour_bvnorm(   mean1 = 0,   sd1 = 1,   mean2 = 0,   sd2 = 1,   cor12 = 0,   cov12 = NULL,   density = 0.95,   length_out = 101,   bty = \"L\",   ... )"},{"path":"https://mmm-usc.github.io/unbiasr/reference/contour_bvnorm.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Plot contour for a bivariate normal distribution — contour_bvnorm","text":"mean1 Mean first normal distribution (x-axis). sd1 Standard deviation thefirst normal distribution. mean2 Mean second normal distribution (y-axis). sd2 Standard deviation second normal distribution. cor12 Correlation bivariate normal distribution. cov12 Covariance bivariate normal distribution. input, compute covariance using correlation standard deviations. density Density level, .e., probability enclosed ellipse. length_out Number values x-axis y-axis evaluated; default 101. bty Argument passed contour function. ... Additional arguments passed contour","code":""},{"path":"https://mmm-usc.github.io/unbiasr/reference/contour_bvnorm.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Plot contour for a bivariate normal distribution — contour_bvnorm","text":"plot showing contour bivariate normal distribution two-dimensional space.","code":""},{"path":"https://mmm-usc.github.io/unbiasr/reference/contour_bvnorm.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Plot contour for a bivariate normal distribution — contour_bvnorm","text":"","code":"if (FALSE) { contour_bvnorm(   0.5, 1, 0.57, 1.03, cov12 = 0.8,   xlab = bquote(\"Latent Composite\" ~ (zeta)),   ylab = bquote(\"Observed Composite\" ~ (italic(Z))),   lwd = 2, col = \"red\", xlim = c(-3.0, 3.5),   ylim = c(-2.97, 3.67) ) }"},{"path":"https://mmm-usc.github.io/unbiasr/reference/delta_h.html","id":null,"dir":"Reference","previous_headings":"","what":"Compute effect size for the impact of item deletion — delta_h","title":"Compute effect size for the impact of item deletion — delta_h","text":"delta_h Computes effect size impact item bias comparing Cohen's h values CAI full versus delete-one item sets.","code":""},{"path":"https://mmm-usc.github.io/unbiasr/reference/delta_h.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Compute effect size for the impact of item deletion — delta_h","text":"","code":"delta_h(h_R, h_i_del)"},{"path":"https://mmm-usc.github.io/unbiasr/reference/delta_h.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Compute effect size for the impact of item deletion — delta_h","text":"h_R h effect sizes item included. h_i_del h effect sizes item deleted.","code":""},{"path":"https://mmm-usc.github.io/unbiasr/reference/delta_h.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Compute effect size for the impact of item deletion — delta_h","text":"Cohen's h difference classification accuracy index item deleted.","code":""},{"path":"https://mmm-usc.github.io/unbiasr/reference/delta_h.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Compute effect size for the impact of item deletion — delta_h","text":"","code":"delta_h(0.04, 0.01) #> [1] 0.03 delta_h(-0.002, 0.011) #> [1] -0.009"},{"path":"https://mmm-usc.github.io/unbiasr/reference/determine_biased_items.html","id":null,"dir":"Reference","previous_headings":"","what":"Determine biased items — determine_biased_items","title":"Determine biased items — determine_biased_items","text":"determine_biased_items takes factor loadings, intercepts, uniqueness reference focal groups, returns indices noninvariant items.","code":""},{"path":"https://mmm-usc.github.io/unbiasr/reference/determine_biased_items.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Determine biased items — determine_biased_items","text":"","code":"determine_biased_items(lambda_r, lambda_f, nu_r, nu_f, Theta_r, Theta_f)"},{"path":"https://mmm-usc.github.io/unbiasr/reference/determine_biased_items.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Determine biased items — determine_biased_items","text":"lambda_r Factor loadings reference group. lambda_f Factor loadings focal group. nu_r Measurement intercepts reference group. nu_f Measurement intercepts focal group. Theta_r Uniqueness reference group. Theta_f Uniqueness focal group.","code":""},{"path":"https://mmm-usc.github.io/unbiasr/reference/determine_biased_items.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Determine biased items — determine_biased_items","text":"vector containing indices biased items.","code":""},{"path":"https://mmm-usc.github.io/unbiasr/reference/determine_biased_items.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Determine biased items — determine_biased_items","text":"","code":"lambda_matrix <- matrix(0, nrow = 5, ncol = 2) lambda_matrix[1:2, 1] <- c(.322, .655) lambda_matrix[3:5, 2] <- c(.398, .745, .543) determine_biased_items(lambda_r = lambda_matrix,                        lambda_f = lambda_matrix,                        nu_r = c(.225, .025, .010, .240, .125),                        nu_f = c(.225, -.05, .240, -.025, .125),                        Theta_r = diag(1, 5),                        Theta_f = diag(c(1, .95, .80, .75, 1))) #> [1] 2 3 4"},{"path":"https://mmm-usc.github.io/unbiasr/reference/dot-bvnorm_kernel.html","id":null,"dir":"Reference","previous_headings":"","what":"Helper function for computing the kernel for bivariate normal density. — .bvnorm_kernel","title":"Helper function for computing the kernel for bivariate normal density. — .bvnorm_kernel","text":".bvnorm_kernel returns kernel bivariate normal density","code":""},{"path":"https://mmm-usc.github.io/unbiasr/reference/dot-bvnorm_kernel.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Helper function for computing the kernel for bivariate normal density. — .bvnorm_kernel","text":"","code":".bvnorm_kernel(x, y, mu_x = 0, mu_y = 0, sd_x = 1, sd_y = 1, cov_xy = 0)"},{"path":"https://mmm-usc.github.io/unbiasr/reference/dot-bvnorm_kernel.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Helper function for computing the kernel for bivariate normal density. — .bvnorm_kernel","text":"x normal distribution y normal distribution mu_x Mean normal distribution x. mu_y Mean normal distribution y. sd_x Standard deviation normal distribution x. sd_y Standard deviation normal distribution y. cov_xy covariance x y","code":""},{"path":"https://mmm-usc.github.io/unbiasr/reference/dot-bvnorm_kernel.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Helper function for computing the kernel for bivariate normal density. — .bvnorm_kernel","text":"output quantile corresponding p \\(1 - q\\) mixture normal distribution.","code":""},{"path":"https://mmm-usc.github.io/unbiasr/reference/dot-bvnorm_kernel.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Helper function for computing the kernel for bivariate normal density. — .bvnorm_kernel","text":"","code":"if (FALSE) { .bvnorm_kernel(x = -2.50, y = -2.52, mu_x = 1, mu_y = 0.57, sd_x = 1, sd_y = 1.03, cov_xy = 0.8) }"},{"path":"https://mmm-usc.github.io/unbiasr/reference/dot-partit_bvnorm.html","id":null,"dir":"Reference","previous_headings":"","what":"Computing summary statistics from a selection approach — .partit_bvnorm","title":"Computing summary statistics from a selection approach — .partit_bvnorm","text":".partit_bvnorm returns table selection accuracy indices","code":""},{"path":"https://mmm-usc.github.io/unbiasr/reference/dot-partit_bvnorm.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Computing summary statistics from a selection approach — .partit_bvnorm","text":"","code":".partit_bvnorm(   cut1,   cut2,   mean1 = 0,   sd1 = 1,   mean2 = 0,   sd2 = 1,   cor12 = 0,   cov12 = cor12 * sd1 * sd2 )"},{"path":"https://mmm-usc.github.io/unbiasr/reference/dot-partit_bvnorm.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Computing summary statistics from a selection approach — .partit_bvnorm","text":"cut1 Cut score based latent score cut2 Cut score based observed score mean1 Mean first normal distribution (x-axis). sd1 Standard deviation first normal distribution. mean2 Mean second normal distribution (y-axis). sd2 Standard deviation second normal distribution. cor12 Correlation bivariate normal. cov12 Covariance bivariate normal. input, compute covariance using correlation standard deviations.","code":""},{"path":"https://mmm-usc.github.io/unbiasr/reference/dot-partit_bvnorm.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Computing summary statistics from a selection approach — .partit_bvnorm","text":"table selection accuracy indices","code":""},{"path":"https://mmm-usc.github.io/unbiasr/reference/dot-partit_bvnorm.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Computing summary statistics from a selection approach — .partit_bvnorm","text":"","code":"if (FALSE) { .partit_bvnorm(cut1 = 2, cut2 = 2, mean1 = 0, sd1 = 1,                 mean2 = 1.53, sd2 = 0.89, cov12 = 0.80) }"},{"path":"https://mmm-usc.github.io/unbiasr/reference/err_improv_acai.html","id":null,"dir":"Reference","previous_headings":"","what":"Check for misleading improvements in aggregate CAI — err_improv_acai","title":"Check for misleading improvements in aggregate CAI — err_improv_acai","text":"err_improv_acai checks improvement observed aggregate CAI may resulted higher mixing proportion reference group masking worsening performance focal group. effect size change indicating worse performance focal group better performance reference group larger 0.1, prints warning message.","code":""},{"path":"https://mmm-usc.github.io/unbiasr/reference/err_improv_acai.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Check for misleading improvements in aggregate CAI — err_improv_acai","text":"","code":"err_improv_acai(i, store_summary_full, store_summary_del1)"},{"path":"https://mmm-usc.github.io/unbiasr/reference/err_improv_acai.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Check for misleading improvements in aggregate CAI — err_improv_acai","text":"Index item consideration. store_summary_full PartInv summary case items retained. store_summary_del1 PartInv summary case item excluded.","code":""},{"path":"https://mmm-usc.github.io/unbiasr/reference/format_cfa_partinv.html","id":null,"dir":"Reference","previous_headings":"","what":"Extract and format parameter values for PartInv. — format_cfa_partinv","title":"Extract and format parameter values for PartInv. — format_cfa_partinv","text":"format_cfa_partinv takes lavaan CFA fit object component returns necessary inputs PartInv list","code":""},{"path":"https://mmm-usc.github.io/unbiasr/reference/format_cfa_partinv.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Extract and format parameter values for PartInv. — format_cfa_partinv","text":"","code":"format_cfa_partinv(obj, comp)"},{"path":"https://mmm-usc.github.io/unbiasr/reference/format_cfa_partinv.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Extract and format parameter values for PartInv. — format_cfa_partinv","text":"obj lavaan CFA output comp string indicating lavaan object component interest e.g., \"se\", \"est\"","code":""},{"path":"https://mmm-usc.github.io/unbiasr/reference/format_cfa_partinv.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Extract and format parameter values for PartInv. — format_cfa_partinv","text":"output list 5 elements: nu list length g containing 1 x n measurement intercept vectors g number groups n number items scale. alpha list length g containing 1 x d latent factor mean vectors g number groups d number latent dimensions. lambda list length g containing n x d factor loading matrices g number groups, d number latent dimensions, n number items scale. psi list length g containing d x d latent factor variance-covariance matrices g number groups d number latent dimensions. theta list length g containing 1 x n vectors n x n matrices unique factor variances covariances, g number groups n number items scale.","code":""},{"path":"https://mmm-usc.github.io/unbiasr/reference/get_aggregate_CAI.html","id":null,"dir":"Reference","previous_headings":"","what":"Compute PS, SR, SE, SP weighted by group proportions — get_aggregate_CAI","title":"Compute PS, SR, SE, SP weighted by group proportions — get_aggregate_CAI","text":"get_aggregate_CAI computes aggregate PS, SR, SE, SP partial strict invariance weighting TP, TF, TN, FP values reference focal groups group proportions.","code":""},{"path":"https://mmm-usc.github.io/unbiasr/reference/get_aggregate_CAI.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Compute PS, SR, SE, SP weighted by group proportions — get_aggregate_CAI","text":"","code":"get_aggregate_CAI(pmixr, store_summary)"},{"path":"https://mmm-usc.github.io/unbiasr/reference/get_aggregate_CAI.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Compute PS, SR, SE, SP weighted by group proportions — get_aggregate_CAI","text":"pmixr Proportion reference group. store_summary summary table PartInv() partial strict invariance.","code":""},{"path":"https://mmm-usc.github.io/unbiasr/reference/get_aggregate_CAI.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Compute PS, SR, SE, SP weighted by group proportions — get_aggregate_CAI","text":"vector length 4. PS Proportion selected, computed \\(TP + FP\\). SR Success ratio, computed \\(TP/(TP + FP)\\). SE Sensitivity, computed \\(TP/(TP + FN)\\). SP Specificity, computed \\(TN/(TN + FP)\\).","code":""},{"path":"https://mmm-usc.github.io/unbiasr/reference/item_deletion_h.html","id":null,"dir":"Reference","previous_headings":"","what":"Impact of deleting biased item(s) on classification accuracy indices — item_deletion_h","title":"Impact of deleting biased item(s) on classification accuracy indices — item_deletion_h","text":"item_deletion_h computes effect size indices quantify impact (changes impact ) measurement bias classification accuracy indices (CAI) TP SE item dropped vs. included analyses. Comparisons made CAI computed reference group expected CAI computed focal group; CAI computed strict factorial invariance (SFI) vs. CAI computed partial factorial invariance (PFI); aggregate CAI computed item subsets.","code":""},{"path":"https://mmm-usc.github.io/unbiasr/reference/item_deletion_h.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Impact of deleting biased item(s) on classification accuracy indices — item_deletion_h","text":"","code":"item_deletion_h(   propsel = NULL,   cut_z = NULL,   weights_item,   weights_latent,   alpha_r,   alpha_f = alpha_r,   psi_r,   psi_f = psi_r,   lambda_r,   lambda_f = lambda_r,   nu_r,   nu_f = nu_r,   Theta_r,   Theta_f = Theta_r,   pmix_ref = 0.5,   plot_contour = TRUE,   show_mi_result = TRUE,   labels = c(\"Reference\", \"Focal\"),   n_dim = 1,   n_i_per_dim = NULL,   user_specified_items = NULL,   delete_one_cutoff = NULL,   ... )"},{"path":"https://mmm-usc.github.io/unbiasr/reference/item_deletion_h.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Impact of deleting biased item(s) on classification accuracy indices — item_deletion_h","text":"propsel Proportion selection. missing, computed using cut_z. cut_z Pre-specified cutoff score observed composite. argument ignored propsel input. weights_item vector item weights. weights_latent  vector latent factor weights. alpha_r vector latent factor mean reference group. alpha_f (optional) vector latent factor mean focal group; input, set equal alpha_r. psi_r matrix latent factor variance covariances reference group. psi_f (optional) matrix latent factor variance-covariances focal group; input, set equal psi_r. lambda_r matrix factor loadings reference group. lambda_f (optional) matrix factor loadings focal group; input, set equal lambda_r. nu_r matrix measurement intercepts reference group partial invariance condition. nu_f (optional) matrix measurement intercepts focal group; input, set equal nu_r. Theta_r matrix unique factor variances covariances reference group. Theta_f (optional) matrix unique factor variances covariances focal group; input, set equal Theta_r. pmix_ref Proportion reference group; default 0.5 (.e., two populations equal size). plot_contour Logical; whether contour two populations plotted; default TRUE. show_mi_result TRUE, perform classification accuracy analysis input parameters implied parameters based strict invariance model, common parameter values weighted averages input values using pmix_ref. labels character vector two elements label reference focal group graph. n_dim Number dimensions, 1 default. user supply different value, proceeds assumption scale unidimensional. n_i_per_dim vector containing number items dimension; NULL default. user provides value n_dim \\(> 1\\) leaves n_i_per_dim = NULL, assumes subscales equal number items. user_specified_items vector; default NULL. user input vector items, items determined contain bias considered deletion. delete_one_cutoff (optional) User-specified cutoff use delete-one scenarios. NULL default; NULL, proportion selected SFI PFI full item set used passed onto calls PartInv. ... arguments passed contour function.","code":""},{"path":"https://mmm-usc.github.io/unbiasr/reference/item_deletion_h.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Impact of deleting biased item(s) on classification accuracy indices — item_deletion_h","text":"object class itemdeletion containing 13 elements. ACAI matrix stores aggregate PS, SR, SE, SP computed full set items item subsets excluding biased user specified items PFI. h ACAI (deletion) matrix stores Cohen's h computed impact deleting item considered ACAI table. h ACAI SFI-PFI matrix stores Cohen's h values quantifying discrepancy ACAI SFI vs. ACAI PFI. delta h ACAI SFI-PFI (deletion) matrix stores delta h values quantifying impact deleting item discrepancy ACAI SFI vs. ACAI PFI subsets items. AI Ratio matrix storing Adverse Impact Ratio values computed item subsets invariance condition. h CAI Ref-EF matrix stores Cohen's h values quantifying discrepancy CAI computed reference group expected CAI computed focal group matched distribution reference group (Efocal), PFI subsets items. delta h CAI Ref-EF (deletion) matrix stores delta h values quantifying impact deleting item discrepancy CAI reference vs. Efocal groups PFI. h CAI SFI-PFI list containing two items, ref foc matrices storing Cohen's h values quantifying discrepancy CAI SFI vs. PFI reference group focal group respectively, subsets items. delta h SFI-PFI (deletion) list containing two items, ref foc matrices storing delta h values quantifying impact deleting item discrepancy CAI SFI vs. PFI reference group focal group respectively, subsets items. h SFI-PFI groups Two lists (reference focal). lists contain tables item deletion scenario displaying raw CAI SFI, PFI, Cohen's h value associated difference invariance condition. PartInv Two lists (strict partial), containing PartInv() outputs. return_items vector containing items considered deletion.","code":""},{"path":"https://mmm-usc.github.io/unbiasr/reference/item_deletion_h.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Impact of deleting biased item(s) on classification accuracy indices — item_deletion_h","text":"","code":"# Multidimensional example lambda_matrix <- matrix(0, nrow = 5, ncol = 2) lambda_matrix[1:2, 1] <- c(.322, .655) lambda_matrix[3:5, 2] <- c(.398, .745, .543)  multi_dim <- item_deletion_h(   propsel = .05, n_dim = 5,   weights_item = c(1 / 4, 1 / 4, 1 / 6, 1 / 6, 1 / 6),   weights_latent = c(0.5, 0.5),   alpha_r = c(0, 0),   alpha_f = c(-0.3, 0.1),   psi_r = matrix(c(1, 0.5, 0.5, 1), nrow = 2),   lambda_r = lambda_matrix,   nu_r = c(.225, .025, .010, .240, .125),   nu_f = c(.225, -.05, .240, -.025, .125),   Theta_r = diag(1, 5),   Theta_f = diag(c(1, .95, .80, .75, 1)),   plot_contour = TRUE )                       # Single dimension example single_dim <- item_deletion_h(   propsel = .10,   weights_item = c(1, 0.9, 0.8, 1),   weights_latent = 0.9,   alpha_r = 0.5,   alpha_f = 0,   psi_r = 1,   lambda_r = c(.3, .5, .9, .7),   nu_r = c(.225, .025, .010, .240),   nu_f = c(.225, -.05, .240, -.025),   Theta_r = diag(.96, 4),   n_dim = 1, plot_contour = TRUE )"},{"path":"https://mmm-usc.github.io/unbiasr/reference/lab_cai.html","id":null,"dir":"Reference","previous_headings":"","what":"Convert acronym of composite index to full form. — lab_cai","title":"Convert acronym of composite index to full form. — lab_cai","text":"lab_cai takes string (PS, SR, SE, SP) returns string full form.","code":""},{"path":"https://mmm-usc.github.io/unbiasr/reference/lab_cai.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Convert acronym of composite index to full form. — lab_cai","text":"","code":"lab_cai(cai)"},{"path":"https://mmm-usc.github.io/unbiasr/reference/lab_cai.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Convert acronym of composite index to full form. — lab_cai","text":"cai two-letter string indicating classification accuracy index.","code":""},{"path":"https://mmm-usc.github.io/unbiasr/reference/lab_cai.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Convert acronym of composite index to full form. — lab_cai","text":"output string.","code":""},{"path":"https://mmm-usc.github.io/unbiasr/reference/mn_sd_cov.html","id":null,"dir":"Reference","previous_headings":"","what":"Compute the mean, standard deviation, and covariance of latent and observed variables. — mn_sd_cov","title":"Compute the mean, standard deviation, and covariance of latent and observed variables. — mn_sd_cov","text":"mn_sd_cov helper function computes mean, standard deviation, covariance latent observed variables group.","code":""},{"path":"https://mmm-usc.github.io/unbiasr/reference/mn_sd_cov.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Compute the mean, standard deviation, and covariance of latent and observed variables. — mn_sd_cov","text":"","code":"mn_sd_cov(weights_item, weights_latent, alpha, psi, lambda, nu, theta)"},{"path":"https://mmm-usc.github.io/unbiasr/reference/mn_sd_cov.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Compute the mean, standard deviation, and covariance of latent and observed variables. — mn_sd_cov","text":"weights_item vector item weights. weights_latent vector latent factor weights. alpha list length g containing 1 x d latent factor mean vectors g number groups d number latent dimensions. first element assumed belong reference group. psi list length g containing d x d latent factor variance-covariance matrices g number groups d number latent dimensions. first element assumed belong reference group. lambda list length g containing n x d factor loading matrices g number groups, d number latent dimensions, n number items scale. first element assumed belong reference group. nu list length g containing 1 x n measurement intercept vectors g number groups n number items scale. first element assumed belong reference group. theta list length g containing 1 x n vectors n x n matrices unique factor variances covariances, g number groups n number items scale. first element assumed belong reference group.","code":""},{"path":"https://mmm-usc.github.io/unbiasr/reference/mn_sd_cov.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Compute the mean, standard deviation, and covariance of latent and observed variables. — mn_sd_cov","text":"output list 5 elements: mn_z Mean observed variable. sd_z Standard deviation observed variable. mn_xi Mean latent variable. sd_xi Standard deviation latent variable. cov_z_xi Covariance latent observed variables.","code":""},{"path":"https://mmm-usc.github.io/unbiasr/reference/myApp.html","id":null,"dir":"Reference","previous_headings":"","what":"Launching Partial Invariance Evaluation Shinyapp — myApp","title":"Launching Partial Invariance Evaluation Shinyapp — myApp","text":"launch, myApp launch Shinyapp designed use Multidimensional Classification Accuracy Analysis (MCAA) Framework evaluating measurement invariance personnel selection context.","code":""},{"path":"https://mmm-usc.github.io/unbiasr/reference/myApp.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Launching Partial Invariance Evaluation Shinyapp — myApp","text":"","code":"myApp(...)  launch(...)"},{"path":"https://mmm-usc.github.io/unbiasr/reference/myApp.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Launching Partial Invariance Evaluation Shinyapp — myApp","text":"... Currently used.","code":""},{"path":"https://mmm-usc.github.io/unbiasr/reference/myApp.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Launching Partial Invariance Evaluation Shinyapp — myApp","text":"app three pages Instruction: Provides direction Shinyapp Single dimension: Implements CAA framework single dimensional constructs Multiple dimensions: Implements MCAA framework multidimensional constructs","code":""},{"path":"https://mmm-usc.github.io/unbiasr/reference/myApp.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Launching Partial Invariance Evaluation Shinyapp — myApp","text":"","code":"if (FALSE) { myApp() launch() }"},{"path":"https://mmm-usc.github.io/unbiasr/reference/plot.PartInv.html","id":null,"dir":"Reference","previous_headings":"","what":"Contour plots for multiple groups. — plot.PartInv","title":"Contour plots for multiple groups. — plot.PartInv","text":"plot.PartInv plots contours number groups.","code":""},{"path":"https://mmm-usc.github.io/unbiasr/reference/plot.PartInv.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Contour plots for multiple groups. — plot.PartInv","text":"","code":"# S3 method for PartInv plot(   x,   labels = x[[\"labels\"]],   which_result = c(\"pi\", \"mi\"),   custom_colors = NULL,   ... )"},{"path":"https://mmm-usc.github.io/unbiasr/reference/plot.PartInv.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Contour plots for multiple groups. — plot.PartInv","text":"x PartInv output. labels default, c(\"Reference\", \"Focal_1\", ..., \"Focal_g\") g number groups. which_result Whether plot partial strict invariance plot. custom_colors Optional argument specifying colors ellipses. ... Additional arguments.","code":""},{"path":"https://mmm-usc.github.io/unbiasr/reference/plotPropselRange.html","id":null,"dir":"Reference","previous_headings":"","what":"Plot classification accuracy indices at different proportions of selection or at different threshold (cutoff) values — plotPropselRange","title":"Plot classification accuracy indices at different proportions of selection or at different threshold (cutoff) values — plotPropselRange","text":"plotPropselRange plots classification accuracy indices different proportions selection partial strict invariance conditions given CFA fit.","code":""},{"path":"https://mmm-usc.github.io/unbiasr/reference/plotPropselRange.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Plot classification accuracy indices at different proportions of selection or at different threshold (cutoff) values — plotPropselRange","text":"","code":"plotPropselRange(   cfa_fit,   pmix = NULL,   labels = NULL,   cai_names = c(\"PS\", \"SR\", \"SE\", \"SP\", \"AI\"),   mod_names = c(\"par\", \"str\"),   from = 0.01,   to = 0.25,   by = 0.01,   cutoffs_from = NULL,   cutoffs_to = NULL )"},{"path":"https://mmm-usc.github.io/unbiasr/reference/plotPropselRange.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Plot classification accuracy indices at different proportions of selection or at different threshold (cutoff) values — plotPropselRange","text":"cfa_fit CFA model output lavaan. pmix List length g containing mixing proportions group (g number groups). NULL, defaults 1/g group (.e., populations equal size). labels character vector g elements label reference focal groups plot, g number groups. provided, groups labeled automatically 'Reference' (first group) 'Focal_1' 'Focal_(g-1)', g number groups. cai_names vector strings indicating classification accuracy indices interest. c(\"PS\", \"SR\", \"SE\", \"SP\", \"AI) default. mod_names vector strings indicating invariance conditions interest. c(\"par\", \"str\") default. lowest proportion selection consider. 0.01 default. largest proportion selection consider. 0.25 default. increment sequence proportions. 0.01 default. cutoffs_from lowest threshold consider.NULL default. cutoffs_to largest threshold consider. NULL default.","code":""},{"path":"https://mmm-usc.github.io/unbiasr/reference/plotPropselRange.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Plot classification accuracy indices at different proportions of selection or at different threshold (cutoff) values — plotPropselRange","text":"Eight plots illustrating proportion selected (PS), success ratio (SR), sensitivity (SE), specificity (SP) change across different proportions selection partial strict invariance conditions.","code":""},{"path":"https://mmm-usc.github.io/unbiasr/reference/plotPropselRange.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Plot classification accuracy indices at different proportions of selection or at different threshold (cutoff) values — plotPropselRange","text":"","code":"if (FALSE) { library(lavaan) HS <- HolzingerSwineford1939 HS$sex <- as.factor(HS$sex) HS.model <- ' visual  =~ x1 + x2 + x3               textual =~ x4 + x5 + x6               speed   =~ x7 + x8 + x9 '  fit <- cfa(HS.model, data = HS, group = \"sex\")  # plot CAI at different proportions of selection plotPropselRange(fit, pmix = table(HS$sex)/sum(table(HS$sex)))  # plot CAI at different cutoffs plotPropselRange(fit, pmix = table(HS$sex)/sum(table(HS$sex)),     cutoffs_from = 35, cutoffs_to = 50)  # plot only SR under partial invariance for up to 10% selection. plotPropselRange(fit, pmix = table(HS$sex)/sum(table(HS$sex)),      from = 0.01, to = 0.10, cai_names = \"SR\", mod_names = \"par\") }"},{"path":"https://mmm-usc.github.io/unbiasr/reference/pnormmix.html","id":null,"dir":"Reference","previous_headings":"","what":"Distribution function (pdf) of a mixture of two normal distributions. — pnormmix","title":"Distribution function (pdf) of a mixture of two normal distributions. — pnormmix","text":"pnormmix returns cumulative probability q \\(1 - q\\) mixture normal distribution.","code":""},{"path":"https://mmm-usc.github.io/unbiasr/reference/pnormmix.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Distribution function (pdf) of a mixture of two normal distributions. — pnormmix","text":"","code":"pnormmix(   q,   mean1 = 0,   sd1 = 1,   mean2 = 0,   sd2 = 1,   pmix1 = 0.5,   lower.tail = TRUE )"},{"path":"https://mmm-usc.github.io/unbiasr/reference/pnormmix.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Distribution function (pdf) of a mixture of two normal distributions. — pnormmix","text":"q vector quantiles. mean1 Mean first normal distribution. sd1 Standard deviation first normal distribution. mean2 Mean second normal distribution. sd2 Standard deviation second normal distribution. pmix1 Mixing proportion first distribution. number range (0, 1). lower.tail logical scalar; TRUE (default), probabilities \\(P[X <= x]\\); otherwise, \\(P[X > x]\\).","code":""},{"path":"https://mmm-usc.github.io/unbiasr/reference/pnormmix.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Distribution function (pdf) of a mixture of two normal distributions. — pnormmix","text":"output cumulative probability q \\(1 - q\\) mixture normal distribution.","code":""},{"path":"https://mmm-usc.github.io/unbiasr/reference/pnormmix.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Distribution function (pdf) of a mixture of two normal distributions. — pnormmix","text":"","code":"if (FALSE) { pnormmix(1, 0, 3.1, 1.7, 3.1, lower.tail = FALSE) }"},{"path":"https://mmm-usc.github.io/unbiasr/reference/qnormmix.html","id":null,"dir":"Reference","previous_headings":"","what":"Quantile function of a mixture of two normal distributions. — qnormmix","title":"Quantile function of a mixture of two normal distributions. — qnormmix","text":"qnormmix returns quantile corresponding \\(p\\) \\(1 - q\\) mixture normal distribution.","code":""},{"path":"https://mmm-usc.github.io/unbiasr/reference/qnormmix.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Quantile function of a mixture of two normal distributions. — qnormmix","text":"","code":"qnormmix(   p,   mean1 = 0,   sd1 = 1,   mean2 = 0,   sd2 = 1,   pmix1 = 0.5,   lower.tail = TRUE )"},{"path":"https://mmm-usc.github.io/unbiasr/reference/qnormmix.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Quantile function of a mixture of two normal distributions. — qnormmix","text":"p vector probabilities. mean1 Mean first normal distribution. sd1 Standard deviation first normal distribution. mean2 Mean second normal distribution. sd2 Standard deviation second normal distribution. pmix1 Mixing proportion first distribution. number range (0, 1). lower.tail logical scalar; TRUE (default), probabilities \\(P[X <= x]\\); otherwise, \\(P[X > x]\\).","code":""},{"path":"https://mmm-usc.github.io/unbiasr/reference/qnormmix.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Quantile function of a mixture of two normal distributions. — qnormmix","text":"output quantile corresponding p \\(1 - q\\) mixture normal distribution.","code":""},{"path":"https://mmm-usc.github.io/unbiasr/reference/qnormmix.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Quantile function of a mixture of two normal distributions. — qnormmix","text":"","code":"if (FALSE) { qnormmix(0.8, 0, 3.1, 1.7, 0.5, lower.tail = FALSE) }"},{"path":"https://mmm-usc.github.io/unbiasr/reference/redistribute_weights.html","id":null,"dir":"Reference","previous_headings":"","what":"Delete item i and redistribute its weight within subscale — redistribute_weights","title":"Delete item i and redistribute its weight within subscale — redistribute_weights","text":"redistribute_weights replaces item weight 0 item deleted, redistributes item's weight across remaining items.","code":""},{"path":"https://mmm-usc.github.io/unbiasr/reference/redistribute_weights.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Delete item i and redistribute its weight within subscale — redistribute_weights","text":"","code":"redistribute_weights(weights_item, n_dim = 1, n_i_per_dim = NULL, del_i)"},{"path":"https://mmm-usc.github.io/unbiasr/reference/redistribute_weights.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Delete item i and redistribute its weight within subscale — redistribute_weights","text":"weights_item vector item weights. n_dim Number dimensions, 1 default. user supply value, assumes scale unidimensional. n_i_per_dim vector containing number items dimension; NULL default. user provides value n_dim \\(> 1\\) leaves n_i_per_dim = NULL, assumes subscales equal number items. del_i Index item deleted.","code":""},{"path":"https://mmm-usc.github.io/unbiasr/reference/redistribute_weights.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Delete item i and redistribute its weight within subscale — redistribute_weights","text":"new_w Weights vector redistributed weights.","code":""},{"path":"https://mmm-usc.github.io/unbiasr/reference/redistribute_weights.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Delete item i and redistribute its weight within subscale — redistribute_weights","text":"","code":"one_dim_w <- c(1:7) redistribute_weights(one_dim_w, del_i = 2) #> [1] 1.076923 0.000000 3.230769 4.307692 5.384615 6.461538 7.538462 redistribute_weights(one_dim_w, n_dim = 1, n_i_per_dim = 7, del_i = 2) #> [1] 1.076923 0.000000 3.230769 4.307692 5.384615 6.461538 7.538462 sum(one_dim_w)==sum(redistribute_weights(one_dim_w, del_i = 2)) #> [1] TRUE  multi_eq_w <- c(1:9) redistribute_weights(multi_eq_w, n_dim = 3, del_i = 2) #> [1] 1.5 0.0 4.5 4.0 5.0 6.0 7.0 8.0 9.0 redistribute_weights(multi_eq_w, n_dim = 3, n_i_per_dim = c(3, 3, 3),  del_i = 2) #> [1] 1.5 0.0 4.5 4.0 5.0 6.0 7.0 8.0 9.0 sum(multi_eq_w)==sum(redistribute_weights(multi_eq_w, n_dim = 3, del_i = 2)) #> [1] TRUE  multi_uneq_w <- c(1:12) redistribute_weights(multi_uneq_w, n_dim = 3, n_i_per_dim = c(3, 6, 3),  del_i=2) #>  [1]  1.5  0.0  4.5  4.0  5.0  6.0  7.0  8.0  9.0 10.0 11.0 12.0 sum(multi_uneq_w)==sum(redistribute_weights(multi_uneq_w, n_dim = 3,                                             n_i_per_dim = c(3, 6, 3),                                             del_i=2)) #> [1] TRUE"},{"path":"https://mmm-usc.github.io/unbiasr/reference/unnest_list.html","id":null,"dir":"Reference","previous_headings":"","what":"Unnest list elements. — unnest_list","title":"Unnest list elements. — unnest_list","text":"unnest_list takes list object returns unnested list lists","code":""},{"path":"https://mmm-usc.github.io/unbiasr/reference/unnest_list.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Unnest list elements. — unnest_list","text":"","code":"unnest_list(ins)"},{"path":"https://mmm-usc.github.io/unbiasr/reference/unnest_list.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Unnest list elements. — unnest_list","text":"ins list object (e.g., lavaan CFA fit)","code":""},{"path":"https://mmm-usc.github.io/unbiasr/reference/unnest_list.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Unnest list elements. — unnest_list","text":"output list lists.","code":""}]
